{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "desirable-above",
   "metadata": {},
   "source": [
    "# Multi-Input Text Explanation: Textual Entailment with Facebook BART\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-capitol",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to get explanations for the output of the Facebook BART model trained on the mnli dataset and used for textual entailment. We use an example from the snli dataset due to mnli not being supported in the required environment for shap. \n",
    "\n",
    "BART: https://huggingface.co/facebook/bart-large-mnli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import shap\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-network",
   "metadata": {},
   "source": [
    "### Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"snli\")\n",
    "snli_label_map = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "example_ind = 6\n",
    "premise, hypothesis, label = ( dataset['train']['premise'][example_ind], \n",
    "                              dataset['train']['hypothesis'][example_ind], \n",
    "                              dataset['train']['label'][example_ind] )\n",
    "print('Premise: ' + premise)\n",
    "print('Hypothesis: ' + hypothesis)\n",
    "true_label = snli_label_map[label]\n",
    "print('The true label is: {true_label}'.format(true_label=true_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "logits = model(input_ids)[0]\n",
    "probs = logits.softmax(dim=1)\n",
    "\n",
    "bart_label_map = {0: 'contradiction', 1: 'neutral', 2: 'entailment'}\n",
    "for i, lab in bart_label_map.items():\n",
    "    print('{lab} probability: {prob:0.2f}%'.format(lab=lab, prob=probs[0][i] * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-majority",
   "metadata": {},
   "source": [
    "## Run shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import torch\n",
    "\n",
    "# wrapper function for model\n",
    "# takes in masked string which is in the form: premise <separator token(s)> hypothesis \n",
    "def f(x): \n",
    "    outputs = []\n",
    "    for _x in x:\n",
    "        encoding = torch.tensor([tokenizer.encode(_x)])\n",
    "        output = model(encoding)[0].detach().cpu().numpy() \n",
    "        outputs.append(output[0])\n",
    "    outputs = np.array(outputs)\n",
    "    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
    "    val = sp.special.logit(scores)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct explainer\n",
    "bart_labels = ['contradiction', 'neutral', 'entailment']    \n",
    "explainer = shap.Explainer(f, tokenizer, output_names=bart_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode then decode premise, hypothesis to get concatenated sentences\n",
    "encoded = tokenizer(premise, hypothesis)['input_ids'][1:-1] # ignore the start and end tokens, since tokenizer will naturally add them\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer([decoded]) # wrap input in list\n",
    "print(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-contractor",
   "metadata": {},
   "source": [
    "## Explanation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-martin",
   "metadata": {},
   "source": [
    "## Input Partition Tree - Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = shap_values[0].abs.clustering\n",
    "Z[-1][2] = Z[-2][2] + 10 # last row's distance is extremely large, so make it a more reasonable value\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_arr = shap_values[0].data\n",
    "\n",
    "# # clean labels of unusal characters (only for slow tokenizer, if use_fast=False)\n",
    "# labels_arr = []\n",
    "# for token in shap_values[0].data:\n",
    "#     if token[0] == 'Ä ':\n",
    "#         labels_arr.append(token[1:])\n",
    "#     else:\n",
    "#         labels_arr.append(token)\n",
    "print(labels_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(len(Z) + 20, 15))\n",
    "dn = dendrogram(Z, labels=labels_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-sword",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_order = 'positive'\n",
    "perturbation = 'keep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "sper = benchmark.perturbation.SequentialPerturbation(explainer.model, explainer.masker, sort_order, perturbation)\n",
    "xs, ys, auc = sper.model_score(shap_values, [decoded])\n",
    "sper.plot(xs, ys, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-lounge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

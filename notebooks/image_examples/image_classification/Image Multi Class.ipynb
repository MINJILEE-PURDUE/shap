{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain ResNet50 ImageNet classification using `Partition` explainer\n",
    "\n",
    "This notebook demonstrates how to use SHAP to explain image classification models. In this example we are explaining the output of ResNet50 model for classifying images into 1000 ImageNet classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pre-trained model and data\n",
    "model = ResNet50(weights='imagenet')\n",
    "X, y = shap.datasets.imagenet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting ImageNet 1000 class names\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "with open(shap.datasets.cache(url)) as file:\n",
    "    class_names = [v[1] for v in json.load(file).values()]\n",
    "#print(\"Number of ImageNet classes:\", len(class_names))\n",
    "#print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP ResNet50 model explanation for images \n",
    "\n",
    "Build a partition explainer with:\n",
    " - the model (a python function)\n",
    " - the masker (a python function)\n",
    " - output names (a list of names of the output classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick run with a few evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python function to get model output; replace this function with your own model function. \n",
    "def f(x):\n",
    "    tmp = x.copy()\n",
    "    preprocess_input(tmp)\n",
    "    return model(tmp)\n",
    "\n",
    "# define a masker that is used to mask out partitions of the input image. \n",
    "masker = shap.maskers.Image(\"inpaint_telea\", X[0].shape)\n",
    "\n",
    "# create an explainer with model and image masker \n",
    "explainer = shap.Explainer(f, masker, output_names=class_names)\n",
    "\n",
    "# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(X[1:3], max_evals=100, batch_size=50, outputs=shap.Explanation.argsort.flip[:4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.tile(np.array(shap_values.output_names), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(shap_values.output_names).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.output_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainer options:\n",
    "1. Above image masker uses a blurring technique called \"inpaint_telea\". There are alternate masking options available to experiment with such as \"inpaint_ns\" and \"blur(kernel_xsize, kernel_xsize)\". \n",
    "2. Recommended number of evaluations is 300-500 to get explanations with sufficient granularity for the super pixels. More the number of evaluations, more the granularity but also increases run-time. \n",
    "\n",
    "    Note: `outputs=shap.Explanation.argsort.flip[:4]` has been used in the code above for getting SHAP values because we want to get the top 4 most probable classes for each image i.e. top 4 classes with decreasing probability. Hence, a flip argsort sliced by 4 has been used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing SHAP values output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output with shap values\n",
    "shap.image_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0].base_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0].base_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output with shap values\n",
    "shap.image_plot(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of SHAP output explanation:\n",
    "1. In the first example, given bird image is classified as an American Egret with next probable classes being a Crane, Heron and Flamingo. It is the \"bump\" over the bird's neck that causes it to be classified as an American Egret vs a Crane, Heron or a Flamingo. You can see the neck region of the bird appropriately highlighted in red super pixels.    \n",
    "2. In the second example, it is the shape of the boat which causes it to be classified as a speedboat instead of a fountain, lifeboat or snowplow (appropriately highlighted in red super pixels). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A longer run with many evaluations\n",
    "\n",
    "By increasing the `max_evals` parameter we let SHAP execute the original model more times and so get a more finely detailed explaination. We also use the blur kernel here, both to demonstrate it, and because it is much faster than inpainting. Note that this will take a while if you are not using a modern GPU on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python function to get model output; replace this function with your own model function. \n",
    "def f(x):\n",
    "    tmp = x.copy()\n",
    "    preprocess_input(tmp)\n",
    "    return model(tmp)\n",
    "\n",
    "# define a masker that is used to mask out partitions of the input image. \n",
    "masker_blur = shap.maskers.Image(\"blur(128,128)\", X[0].shape)\n",
    "\n",
    "# create an explainer with model and image masker \n",
    "explainer_blur = shap.Explainer(f, masker_blur, output_names=class_names)\n",
    "\n",
    "# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values_fine = explainer_blur(X[1:3], max_evals=5000, batch_size=50, outputs=shap.Explanation.argsort.flip[:4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output with shap values\n",
    "shap.image_plot(shap_values_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Have an idea for more helpful examples? Pull requests that add to this documentation notebook are encouraged! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

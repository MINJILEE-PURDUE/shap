{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Text - Cumulative SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook below, we will model a text-to-text scenario utilizing cumulative SHAP values to assess the risk using the following steps: \n",
    "\n",
    "A. Defin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_values(n,m):\n",
    "    return [[random.random() for j in range(len(m))] for i in range(len(n))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.016846548893437507, 0.35611691109968857, 0.46951134045911613], [0.7388963539642832, 0.7443198774882204, 0.1392091890479722], [0.6795827637559863, 0.958911087850905, 0.8737470081001293]]\n"
     ]
    }
   ],
   "source": [
    "inputText = ['Bonjour', 'Mon', 'Cheri']\n",
    "outputText = ['Hello', 'My', 'Dear']\n",
    "print (shap_values(inputText, outputText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Harms: \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.harms_map = {} \n",
    "    def add_harm(self, label, harm_map): \n",
    "        self.harms_map[label] = harm_map \n",
    "    def get_harms(self): \n",
    "        return self.harms_map\n",
    "    def create_harm(self, inputs, outputs): \n",
    "        \"\"\"\n",
    "        Create dictionary mapping each individual input to the list of problematic outputs\n",
    "        \n",
    "        Return harm map \n",
    "        \"\"\"\n",
    "        harm_map = {}\n",
    "        for inp in inputs: \n",
    "            harm_map[inp] = outputs\n",
    "        return harm_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Harms class defined above can be used to produce classes of harms, that we can them use to assess risk. We show an examples of classes that could be created below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Discriminatory speech': {'black men': ['are lazy', \"shouldn't drink & use drugs\"], 'black women': ['are lazy', \"shouldn't drink & use drugs\"]}, 'Offensive speech': {'men': ['bad', 'stupid', 'dumb', 'disgusting', 'moron', 'idiot', 'ugly', 'slutty', 'bimbo', 'horrible', 'awful'], 'dogs': ['bad', 'stupid', 'dumb', 'disgusting', 'moron', 'idiot', 'ugly', 'slutty', 'bimbo', 'horrible', 'awful'], 'cats': ['bad', 'stupid', 'dumb', 'disgusting', 'moron', 'idiot', 'ugly', 'slutty', 'bimbo', 'horrible', 'awful'], 'women': ['bad', 'stupid', 'dumb', 'disgusting', 'moron', 'idiot', 'ugly', 'slutty', 'bimbo', 'horrible', 'awful']}, 'Defamation and derogatory speech': {'Obama': ['under arrest', 'fraud', 'scam', 'stealing', 'fired', 'guilty'], 'Trump': ['under arrest', 'fraud', 'scam', 'stealing', 'fired', 'guilty'], 'Biden': ['under arrest', 'fraud', 'scam', 'stealing', 'fired', 'guilty'], 'Pence': ['under arrest', 'fraud', 'scam', 'stealing', 'fired', 'guilty']}}\n"
     ]
    }
   ],
   "source": [
    "harmful_pairs = Harms(\"Harmful Text Predictions\")\n",
    "discrim_inputs = [\"black men\", \"black women\"]\n",
    "discrim_outputs = [\"are lazy\", \"shouldn't drink & use drugs\"]\n",
    "discrim_harm = harmful_pairs.create_harm(discrim_inputs, discrim_outputs)\n",
    "harmful_pairs.add_harm(\"Discriminatory speech\", discrim_harm)\n",
    "\n",
    "normal_inputs = [\"men\", \"dogs\", \"cats\", \"women\"]\n",
    "offensive_outputs = [\"bad\", \"stupid\", \"dumb\",\"disgusting\", \"moron\", \"idiot\", \"ugly\", \"slutty\", \"bimbo\", \"horrible\", \"awful\"]\n",
    "offensive_harm = harmful_pairs.create_harm(normal_inputs, offensive_outputs)\n",
    "harmful_pairs.add_harm(\"Offensive speech\", offensive_harm)\n",
    "\n",
    "defamation_inputs = [\"Obama\", \"Trump\", \"Biden\", \"Pence\"]\n",
    "defamation_outputs = [\"under arrest\", \"fraud\", \"scam\", \"stealing\", \"fired\", \"guilty\"]\n",
    "defamation_harm = harmful_pairs.create_harm(defamation_inputs, defamation_outputs)\n",
    "harmful_pairs.add_harm(\"Defamation and derogatory speech\", defamation_harm)\n",
    "\n",
    "all_harms = harmful_pairs.get_harms()\n",
    "print(all_harms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholder \n",
    "\"\"\"\n",
    "def abs_cumulative_shap(shap_values, word_set): \n",
    "    return abs(mean(shap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholder \n",
    "\"\"\"\n",
    "def pos_cumulative_shap(shap_values, word_set): \n",
    "    return abs(mean(shap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholder \n",
    "\"\"\"\n",
    "def neg_cumulative_shap(shap_values, word_set): \n",
    "    return -1 * abs(mean(shap_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the types of harmful speech, and the prefix-suffix pairings, a user can then use cumulative SHAP to obtain a risk score based on: \n",
    "\n",
    "A. The given dataset for which SHAP values were calculated \n",
    "B. The instances of problematic input-output pairs as defined in their Harms object\n",
    "C. For the words in the wordset, do a separate analysis for each type of harm\n",
    "    Discriminatory speech analysis: \n",
    "    1. Look at the Discriminatory speech harm \n",
    "    2. Check if the texts are in the corpus \n",
    "    3. See the cumulative SHAP value across output tokens? (current)\n",
    "    4. Sum the instances where the output token contains words from the output mapping (proposed)\n",
    "    5. Demonstrate using a dataset which is known to contain the problematic examples vs. not \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

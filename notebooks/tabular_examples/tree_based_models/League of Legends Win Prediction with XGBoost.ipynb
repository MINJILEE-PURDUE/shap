{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpyZm2kikUxY"
   },
   "source": [
    "# League of Legends Win Prediction with XGBoost\n",
    "\n",
    "This notebook uses the Kaggle dataset [League of Legends Ranked Matches](https://www.kaggle.com/paololol/league-of-legends-ranked-matches) which contains 180,000 ranked games of League of Legends starting from 2014. Using this data we build an XGBoost model to predict if a player's team will win based off statistics of how that player played the match.\n",
    "\n",
    "The methods used here are applicable to any dataset, we use this dataset to illustrate how SHAP values help make gradient boosted trees such as XGBoost interpretable because the dataset is large, has many interaction effects, contains both categorical and continous values, and the features are interpretable (particularly for players of the game). For more information on SHAP values see: https://github.com/shap/shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdWasF7PkUxa",
    "outputId": "e9ee993f-2aba-4d88-9045-e617f82e500b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkH0YCR4kUxf"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "To run this yourself you will need to download the dataset from Kaggle and ensure the `prefix` variable below is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShGAdgqIkUxg"
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "prefix = \"../local_scratch/data/league-of-legends-ranked-matches/\"\n",
    "matches = pd.read_csv(prefix+\"matches.csv\")\n",
    "participants = pd.read_csv(prefix+\"participants.csv\")\n",
    "stats1 = pd.read_csv(prefix+\"stats1.csv\", low_memory=False)\n",
    "stats2 = pd.read_csv(prefix+\"stats2.csv\", low_memory=False)\n",
    "stats = pd.concat([stats1,stats2])\n",
    "\n",
    "# merge into a single DataFrame\n",
    "a = pd.merge(participants, matches, left_on=\"matchid\", right_on=\"id\")\n",
    "allstats_orig = pd.merge(a, stats, left_on=\"matchid\", right_on=\"id\")\n",
    "allstats = allstats_orig.copy()\n",
    "\n",
    "# drop games that lasted less than 10 minutes\n",
    "allstats = allstats.loc[allstats[\"duration\"] >= 10*60,:]\n",
    "\n",
    "# Convert string-based categories to numeric values\n",
    "cat_cols = [\"role\", \"position\", \"version\", \"platformid\"]\n",
    "for c in cat_cols:\n",
    "    allstats[c] = allstats[c].astype('category')\n",
    "    allstats[c] = allstats[c].cat.codes\n",
    "allstats[\"wardsbought\"] = allstats[\"wardsbought\"].astype(np.int32)\n",
    "\n",
    "X = allstats.drop([\"win\"], axis=1)\n",
    "y = allstats[\"win\"]\n",
    "\n",
    "# convert all features we want to consider as rates\n",
    "rate_features = [\n",
    "    \"kills\", \"deaths\", \"assists\", \"killingsprees\", \"doublekills\",\n",
    "    \"triplekills\", \"quadrakills\", \"pentakills\", \"legendarykills\",\n",
    "    \"totdmgdealt\", \"magicdmgdealt\", \"physicaldmgdealt\", \"truedmgdealt\",\n",
    "    \"totdmgtochamp\", \"magicdmgtochamp\", \"physdmgtochamp\", \"truedmgtochamp\",\n",
    "    \"totheal\", \"totunitshealed\", \"dmgtoobj\", \"timecc\", \"totdmgtaken\",\n",
    "    \"magicdmgtaken\" , \"physdmgtaken\", \"truedmgtaken\", \"goldearned\", \"goldspent\",\n",
    "    \"totminionskilled\", \"neutralminionskilled\", \"ownjunglekills\",\n",
    "    \"enemyjunglekills\", \"totcctimedealt\", \"pinksbought\", \"wardsbought\",\n",
    "    \"wardsplaced\", \"wardskilled\"\n",
    "]\n",
    "for feature_name in rate_features:\n",
    "    X[feature_name] /= X[\"duration\"] / 60 # per minute rate\n",
    "\n",
    "# convert to fraction of game\n",
    "X[\"longesttimespentliving\"] /= X[\"duration\"]\n",
    "\n",
    "# define friendly names for the features\n",
    "full_names = {\n",
    "    \"kills\": \"Kills per min.\",\n",
    "    \"deaths\": \"Deaths per min.\",\n",
    "    \"assists\": \"Assists per min.\",\n",
    "    \"killingsprees\": \"Killing sprees per min.\",\n",
    "    \"longesttimespentliving\": \"Longest time living as % of game\",\n",
    "    \"doublekills\": \"Double kills per min.\",\n",
    "    \"triplekills\": \"Triple kills per min.\",\n",
    "    \"quadrakills\": \"Quadra kills per min.\",\n",
    "    \"pentakills\": \"Penta kills per min.\",\n",
    "    \"legendarykills\": \"Legendary kills per min.\",\n",
    "    \"totdmgdealt\": \"Total damage dealt per min.\",\n",
    "    \"magicdmgdealt\": \"Magic damage dealt per min.\",\n",
    "    \"physicaldmgdealt\": \"Physical damage dealt per min.\",\n",
    "    \"truedmgdealt\": \"True damage dealt per min.\",\n",
    "    \"totdmgtochamp\": \"Total damage to champions per min.\",\n",
    "    \"magicdmgtochamp\": \"Magic damage to champions per min.\",\n",
    "    \"physdmgtochamp\": \"Physical damage to champions per min.\",\n",
    "    \"truedmgtochamp\": \"True damage to champions per min.\",\n",
    "    \"totheal\": \"Total healing per min.\",\n",
    "    \"totunitshealed\": \"Total units healed per min.\",\n",
    "    \"dmgtoobj\": \"Damage to objects per min.\",\n",
    "    \"timecc\": \"Time spent with crown control per min.\",\n",
    "    \"totdmgtaken\": \"Total damage taken per min.\",\n",
    "    \"magicdmgtaken\": \"Magic damage taken per min.\",\n",
    "    \"physdmgtaken\": \"Physical damage taken per min.\",\n",
    "    \"truedmgtaken\": \"True damage taken per min.\",\n",
    "    \"goldearned\": \"Gold earned per min.\",\n",
    "    \"goldspent\": \"Gold spent per min.\",\n",
    "    \"totminionskilled\": \"Total minions killed per min.\",\n",
    "    \"neutralminionskilled\": \"Neutral minions killed per min.\",\n",
    "    \"ownjunglekills\": \"Own jungle kills per min.\",\n",
    "    \"enemyjunglekills\": \"Enemy jungle kills per min.\",\n",
    "    \"totcctimedealt\": \"Total crown control time dealt per min.\",\n",
    "    \"pinksbought\": \"Pink wards bought per min.\",\n",
    "    \"wardsbought\": \"Wards bought per min.\",\n",
    "    \"wardsplaced\": \"Wards placed per min.\",\n",
    "    \"turretkills\": \"# of turret kills\",\n",
    "    \"inhibkills\": \"# of inhibitor kills\",\n",
    "    \"dmgtoturrets\": \"Damage to turrets\"\n",
    "}\n",
    "feature_names = [full_names.get(n, n) for n in X.columns]\n",
    "X.columns = feature_names\n",
    "\n",
    "# create train/validation split\n",
    "Xt, Xv, yt, yv = train_test_split(X,y, test_size=0.2, random_state=10)\n",
    "dt = xgb.DMatrix(Xt, label=yt.values)\n",
    "dv = xgb.DMatrix(Xv, label=yv.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import shap\n",
    "\n",
    "# df = pd.read_feather(\"data/league.feather\")\n",
    "# X = df.drop('win', axis=1)\n",
    "# y = df['win']\n",
    "\n",
    "# create train/validation split\n",
    "#Xt, Xv, yt, yv = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "ntrees = 5\n",
    "rf = RandomForestClassifier(n_estimators=ntrees, n_jobs=-1)\n",
    "start = timer()\n",
    "rf.fit(Xt, yt)\n",
    "stop = timer()\n",
    "print(f\"RF fit time with {len(Xt)} records and {ntrees} trees = {(stop-start):.2f}s\")\n",
    "\n",
    "Xv_ = Xv[:100] # try with 100 records only\n",
    "Xt_ = Xt[:100]\n",
    "start = timer()\n",
    "explainer = shap.TreeExplainer(rf, Xt_, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer.shap_values(Xv_)\n",
    "stop = timer()\n",
    "print(\"ASDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8X_p5kqkUxi"
   },
   "source": [
    "## Train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UK7gZt4SkUxi",
    "outputId": "4e6d317d-077f-4712-82df-02a6280f8f60"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"eta\": 0.5,\n",
    "    \"max_depth\": 4,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"silent\": 1,\n",
    "    \"base_score\": np.mean(yt),\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "model = xgb.train(params, dt, 3, [(dt, \"train\"), (dv, \"valid\")], early_stopping_rounds=5, verbose_eval=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6XVYqKzTkUxk"
   },
   "source": [
    "## Explain the XGBoost model\n",
    "\n",
    "Because the Tree SHAP algorithm is implemented in XGBoost we can compute exact SHAP values quickly over thousands of samples. The SHAP values for a single prediction (including the expected output in the last column) sum to the model's output for that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ14zE9XkUxl"
   },
   "outputs": [],
   "source": [
    "# compute the SHAP values for every prediction in the validation dataset\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(Xv.iloc[4425:4427], check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value + shap_values.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.model.predict(Xv.iloc[4425:4427])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_additivity(self, phi, model_output):\n",
    "    err_msg = \"Additivity check failed in TreeExplainer! Please report this on GitHub.\"\n",
    "    if self.feature_perturbation != \"interventional\":\n",
    "        err_msg += \" Consider retrying with the feature_perturbation='interventional' option.\"\n",
    "    if type(phi) is list:\n",
    "        for i in range(len(phi)):\n",
    "            val = self.expected_value[i] + phi[i].sum(-1)\n",
    "            assert np.max(np.abs(val - model_output[:,i]) / (np.abs(val) + 1e-2)) < 1e-2, err_msg\n",
    "    else:\n",
    "        val = self.expected_value + phi.sum(-1)\n",
    "        assert np.max(np.abs(val - model_output) / (np.abs(val) + 1e-2)) < 1e-2, err_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_additivity(explainer, shap_values, model.predict(xgb.DMatrix(Xv.iloc[4425:4427]), output_margin=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONDnKgyfkUxn"
   },
   "source": [
    "### Explain a single player's chances of winning a particular match\n",
    "\n",
    "SHAP values sum to the difference between the expected output of the model and the current output for the current player. Note that for the Tree SHAP implementation the margin output of the model is explained, not the trasformed output (such as a probability for logistic regression). This means that the units of the SHAP values for this model are log odds ratios. Large positive values mean a player is likely to win, while large negative values mean they are likely to lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XX0WZQPFkUxn",
    "outputId": "4646828e-dfe9-4df1-e143-a206604cb9c1"
   },
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], Xv.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPV8IbdhkUxp",
    "outputId": "602af046-241c-4cf9-888a-77bfeca27f09"
   },
   "outputs": [],
   "source": [
    "xs = np.linspace(-4,4,100)\n",
    "pl.xlabel(\"Log odds of winning\")\n",
    "pl.ylabel(\"Probability of winning\")\n",
    "pl.title(\"How changes in log odds convert to probability of winning\")\n",
    "pl.plot(xs, 1/(1+np.exp(-xs)))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oj0oSUKykUxr"
   },
   "source": [
    "### Summarize the impact of all features over the entire dataset\n",
    "\n",
    "A SHAP value for a feature of a specific prediction represents how much the model prediction changes when we observe that feature. In the summary plot below we plot all the SHAP values for a single feature (such as `goldearned`) on a row, where the x-axis is the SHAP value (which for this model is in units of log odds of winning). By doing this for all features, we see which features drive the model's prediction a lot (such as `goldearned`), and which only effect the prediction a little (such as `kills`). Note that when points don't fit together on the line they pile up vertically to show density. Each dot is also colored by the value of that feature from high to low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lptjfyu7kUxr",
    "outputId": "3f427ff9-2c25-4020-c2c6-f5130a625cff"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, Xv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOf_jGlQkUxu"
   },
   "source": [
    "## Examine how changes in a feature change the model's prediction\n",
    "\n",
    "The XGBoost model we trained above is very complicated, but by plotting the SHAP value for a feature against the actual value of the feature for all players we can see how changes in the feature's value effect the model's output. Note that these plots are very similar to standard partial dependence plots, but they provide the added advantage of displaying how much context matters for a feature (or in other words how much interaction terms matter). How much interaction terms effect the importance of a feature is capture by the vertical dispersion of the data points. For example earning only 100 gold/min during a game may lower your logg odds of winning by 10 for some players or only 3 for others. Why is this? Because other features of these players effect how much earning gold matters for winning the game. Note that the vertical spread narrows once you earn at least 500 gold/min, meaning the context of other features matters less for high gold earners than low gold earners. We color the datapoints with another feature that most explains the interaction effect variance. For example earning less gold is less bad if you have not died very much, but it is really bad if you also die a lot.\n",
    "\n",
    "The y-axis in the plots below represents the SHAP value for that feature, so -4 means observing that feature lowers your log odds of winning by 4, while a value of +2 means observing that feature raises your log odds of winning by 2.\n",
    "\n",
    "Note that these plot just explain how the XGBoost model works, not nessecarily how reality works. Since the XGBoost model is trained from observational data, it is not nessecarily a causal model, and so just because changing a factor makes the model's prediction of winning go up, does not always mean it will raise your actual chances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ek9Om_lCkUxu",
    "outputId": "e9629d28-aa82-4701-d846-8b5cfc5d860b"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Gold earned per min.\", shap_values, Xv, interaction_index=\"Deaths per min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LXKBPt6kUxw",
    "outputId": "e518ab6e-94d4-43c4-f022-9199956c2851"
   },
   "outputs": [],
   "source": [
    "# sort the features indexes by their importance in the model\n",
    "# (sum of SHAP value magnitudes over the validation dataset)\n",
    "top_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n",
    "\n",
    "# make SHAP plots of the three most important features\n",
    "for i in range(20):\n",
    "    shap.dependence_plot(top_inds[i], shap_values, Xv)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "League of Legends Win Prediction with XGBoost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

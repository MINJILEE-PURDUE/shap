{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import shap\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iml.common import convert_to_instance, convert_to_model, match_instance_to_data, match_model_to_data, convert_to_instance_with_index\n",
    "from iml.explanations import AdditiveExplanation\n",
    "from iml.links import convert_to_link, IdentityLink\n",
    "from iml.datatypes import convert_to_data, DenseData\n",
    "import logging\n",
    "from iml.explanations import AdditiveExplanation\n",
    "\n",
    "log = logging.getLogger('shap')\n",
    "from shap import KernelExplainer\n",
    "class IMEExplainer(KernelExplainer):\n",
    "    \"\"\" This is an implementation of the IME explanation method (aka. Shapley sampling values)\n",
    "    \n",
    "    This is implemented here for comparision and evaluation purposes, the KernelExplainer is\n",
    "    typically more efficient and so is the preferred model agnostic estimation method in this package.\n",
    "    IME was proposed in \"An Efficient Explanation of Individual Classifications using Game Theory\",\n",
    "    Erik Å trumbelj, Igor Kononenko, JMLR 2010\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        # silence warning about large datasets\n",
    "        level = log.level\n",
    "        log.setLevel(logging.ERROR)\n",
    "        super(IMEExplainer, self).__init__(model, data, **kwargs)\n",
    "        log.setLevel(level)\n",
    "    \n",
    "    def explain(self, incoming_instance, **kwargs):\n",
    "        # convert incoming input to a standardized iml object\n",
    "        instance = convert_to_instance(incoming_instance)\n",
    "        match_instance_to_data(instance, self.data)\n",
    "        \n",
    "        # pick a reasonable number of samples if the user didn't specify how many they wanted\n",
    "        self.nsamples = kwargs.get(\"nsamples\", 0)\n",
    "        if self.nsamples == 0:\n",
    "            self.nsamples = 1000 * self.P\n",
    "        \n",
    "        # divide up the samples among the features\n",
    "        self.nsamples_each = np.ones(self.P, dtype=np.int64) * 2 * (self.nsamples // (self.P * 2))\n",
    "        for i in range((self.nsamples % (self.P * 2)) // 2):\n",
    "            self.nsamples_each[i] += 2\n",
    "        \n",
    "        model_out = self.model.f(instance.x)\n",
    "        \n",
    "        # explain every feature\n",
    "        phi = np.zeros(self.P)\n",
    "        self.X_masked = np.zeros((self.nsamples_each.max(), X.shape[1]))\n",
    "        for i in range(self.P):\n",
    "            phi[i] = self.ime(i, self.model.f, instance.x, self.data.data, nsamples=self.nsamples_each[i])\n",
    "        phi = np.array(phi)\n",
    "        \n",
    "        return AdditiveExplanation(self.link.f(1), self.link.f(1), phi, np.zeros(len(phi)), instance, self.link,\n",
    "                                   self.model, self.data)\n",
    "        \n",
    "        \n",
    "    def ime(self, j, f, x, X, nsamples=10):\n",
    "        assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "        X_masked = self.X_masked[:nsamples,:]\n",
    "        inds = np.arange(X.shape[1])\n",
    "\n",
    "        for i in range(0, nsamples//2):\n",
    "            np.random.shuffle(inds)\n",
    "            pos = np.where(inds == j)[0][0]\n",
    "            rind = np.random.randint(X.shape[0])\n",
    "            X_masked[i,:] = x\n",
    "            X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "            X_masked[-(i+1),:] = x\n",
    "            X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "        \n",
    "        s = time.time()\n",
    "        evals = f(X_masked)\n",
    "        #print(\"n\",time.time() - s)\n",
    "        \n",
    "        evals_on = evals[:nsamples//2]\n",
    "        evals_off = evals[nsamples//2:][::-1]\n",
    "        \n",
    "        return np.mean(evals[:nsamples//2] - evals[nsamples//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_shap_times = []\n",
    "sample_times = []\n",
    "Ms = [20,30,40,50,60,70,80,90,100]\n",
    "for M in tqdm(Ms):\n",
    "    \n",
    "    X = np.random.randn(N, M)\n",
    "    y = np.random.randn(N)\n",
    "    model = xgboost.train({\"eta\": 1}, xgboost.DMatrix(X, y), 1000)\n",
    "    \n",
    "    #print()\n",
    "    e = shap.TreeExplainer(model)\n",
    "    s = time.time()\n",
    "    e.shap_values(X)\n",
    "    tree_shap_times.append((time.time() - s)/1000)\n",
    "    #print((time.time() - s)/1000)\n",
    "    \n",
    "    tmp = np.vstack([X for i in range(1 * M)])\n",
    "    s = time.time()\n",
    "    model.predict(xgboost.DMatrix(tmp))\n",
    "    sample_times.append(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(tree_shap_times)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(Ms, np.array(tree_shap_times[:-1])*10000 / (60))\n",
    "pl.plot(Ms, np.array(sample_times[:-1])*10000 / (60))\n",
    "pl.ylabel(\"minutes of runtime\")\n",
    "pl.xlabel(\"# of features\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(tree_shap_times[:-1])*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4995.5940246/5.27129322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4995.5940246/5.27129322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_times[-5]/tree_shap_times[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(sample_times[:-1])*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(10,3))\n",
    "pl.subplot(1, 2, 1)\n",
    "pl.plot(\n",
    "    Ms[:-1], np.array(sample_times[:-1])*10000 / (60),\n",
    "    label=\"Model agnostic sampling\",\n",
    "    color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.plot(\n",
    "    Ms[:-1], np.array(tree_shap_times[:-1])*10000 / (60),\n",
    "    label=\"Tree SHAP\", color=\"#1E88E5\", linewidth=3\n",
    ")\n",
    "pl.ylabel(\"minutes of runtime\\nexplaining 10k predictions\")\n",
    "pl.xlabel(\"# of features in the model\")\n",
    "pl.legend()\n",
    "#pl.savefig(\"runtime.pdf\")\n",
    "#pl.show()\n",
    "\n",
    "pl.subplot(1, 2, 2)\n",
    "pl.plot(\n",
    "    Ms[:-1], (ime_std[:-1] / ime_m[:-1])*100, \"--\",\n",
    "    label=\"IME\", color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.plot(\n",
    "    Ms[:-1], (kernel_shap_std[:-1] / kernel_shap_m[:-1])*100,\n",
    "    label=\"Kernel SHAP\",\n",
    "    color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.plot(\n",
    "    Ms[:-1], np.zeros(len(Ms)-1),\n",
    "    label=\"Tree SHAP\",\n",
    "    color=\"#1E88E5\", linewidth=3\n",
    ")\n",
    "pl.ylabel(\"Std. deviation as % of magnitude\")\n",
    "pl.xlabel(\"# of features in the model\")\n",
    "pl.legend(loc=\"upper left\")\n",
    "pl.savefig(\"perf.pdf\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(\n",
    "    Ms[:-1], (kernel_shap_std[:-1] / kernel_shap_m[:-1])*100,\n",
    "    label=\"Kernel SHAP\",\n",
    "    color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.plot(\n",
    "    Ms[:-1], (ime_std[:-1] / ime_m[:-1])*100, \"--\",\n",
    "    label=\"IME\", color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.ylabel(\"Std. deviation as % of magnitude\")\n",
    "pl.xlabel(\"# of features\")\n",
    "pl.legend(loc=\"upper left\")\n",
    "#pl.savefig(\"std_dev.pdf\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(kernel_shap_std[:-1] / kernel_shap_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(kernel_shap_std[:-1] / kernel_shap_m[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ime_std[:-1] / ime_m[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(\n",
    "    Ms[:-1], (ime_std[:-1] / ime_m[:-1])*100,\n",
    "    label=\"IME\", color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.plot(\n",
    "    Ms[:-1], (kernel_shap_std[:-1] / kernel_shap_m[:-1])*100,\n",
    "    label=\"Kernel SHAP\",\n",
    "    color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.plot(\n",
    "    Ms[:-1], (ime_std[:-1] / ime_m[:-1])*100, \"--\",\n",
    "    label=\"IME\", color=\"#7C52FF\", linewidth=3\n",
    ")\n",
    "pl.ylabel(\"Std. deviation as % of magnitude\")\n",
    "pl.xlabel(\"# of features\")\n",
    "pl.legend(loc=\"upper left\")\n",
    "#pl.savefig(\"std_dev.pdf\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(Ms, kernel_shap_std / kernel_shap_m)\n",
    "pl.plot(Ms, ime_std / ime_m)\n",
    "pl.ylabel(\"minutes of runtime\")\n",
    "pl.xlabel(\"# of features\")\n",
    "pl.plot()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sample_times) / np.array(tree_shap_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(Ms, np.array(tree_shap_times)*10000 / (60*60))\n",
    "pl.plot(Ms, np.array(sample_times)*10000 / (60*60))\n",
    "pl.ylabel(\"hours of runtime\")\n",
    "pl.xlabel(\"# of features\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.semilogy(Ms, tree_shap_times)\n",
    "pl.semilogy(Ms, sample_times)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.1067/0.00056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "model.predict(xgboost.DMatrix(X[:100,:]))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X_full = np.random.randn(N, 100)\n",
    "y = np.random.randn(N)\n",
    "\n",
    "tree_shap_times = []\n",
    "kernel_shap_times = []\n",
    "ime_times = []\n",
    "tree_shap_std = []\n",
    "kernel_shap_std = []\n",
    "kernel_shap_m = []\n",
    "ime_std = []\n",
    "ime_m = []\n",
    "for M in [20,30,40,50,60,70,80,90,100]:#,30,40,50]:\n",
    "    print(\"\\nM\", M)\n",
    "    X = X_full[:,:M]\n",
    "    \n",
    "    model = xgboost.train({\"eta\": 1}, xgboost.DMatrix(X, y), 1000)\n",
    "\n",
    "    def f(x):\n",
    "        return model.predict(xgboost.DMatrix(x))\n",
    "    \n",
    "    e = shap.TreeExplainer(model)\n",
    "    start = time.time()\n",
    "    e.shap_values(X)\n",
    "    iter_time = (time.time() - start)/X.shape[0]\n",
    "    tree_shap_times.append(iter_time)\n",
    "    tree_shap_std.append(0)\n",
    "    \n",
    "    e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "    nsamples = 1000 * M\n",
    "    start = time.time()\n",
    "    out = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)])\n",
    "    std_dev = out.std(0)[:-1].mean()\n",
    "    mval = np.abs(out.mean(0))[:-1].mean()\n",
    "    kernel_shap_m.append(mval)\n",
    "    iter_time = (time.time() - start)/50\n",
    "    kernel_shap_times.append(iter_time)\n",
    "    kernel_shap_std.append(std_dev)\n",
    "    print(std_dev, mval, std_dev / mval)\n",
    "    print(\"KernelExplainer\", iter_time)\n",
    "    \n",
    "    e = IMEExplainer(f, X.mean(0).reshape(1,M))\n",
    "    nsamples = 1000 * M\n",
    "    start = time.time()\n",
    "    out = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)])\n",
    "    std_dev = out.std(0)[:-1].mean()\n",
    "    mval = np.abs(out.mean(0))[:-1].mean()\n",
    "    ime_m.append(mval)\n",
    "    iter_time = (time.time() - start)/50\n",
    "    ime_times.append(iter_time)\n",
    "    ime_std.append(std_dev)\n",
    "    print(std_dev, mval, std_dev / mval)\n",
    "    print(\"IMEExplainer\", iter_time)\n",
    "\n",
    "ime_std = np.array(ime_std)\n",
    "ime_m = np.array(ime_m)\n",
    "kernel_shap_std = np.array(kernel_shap_std)\n",
    "kernel_shap_m = np.array(kernel_shap_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ime_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ime_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shap_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shap_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tree_shap_times = []\n",
    "kernel_shap_times = []\n",
    "ime_times = []\n",
    "nreps = 10\n",
    "\n",
    "N = 1000\n",
    "X_full = np.random.randn(N, 20)\n",
    "y = np.random.randn(N)\n",
    "\n",
    "for M in range(4,8):\n",
    "    ts = []\n",
    "    tree_shap_time = 0\n",
    "    kernel_shap_time = 0\n",
    "    ime_time = 0\n",
    "    for k in tqdm(range(nreps)):\n",
    "#         print()\n",
    "         #+ ((X > 0).sum(1) % 2)\n",
    "        X = X_full[:,:M]\n",
    "\n",
    "        model = xgboost.train({\"eta\": 1}, xgboost.DMatrix(X, y), 1000)\n",
    "\n",
    "        def f(x):\n",
    "            return model.predict(xgboost.DMatrix(x))\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        shap_values = shap.TreeExplainer(model).shap_values(X)\n",
    "        tree_shap_time += time.time() - start\n",
    "#         print(\"Tree SHAP:\", tree_shap_time, \"seconds\")\n",
    "\n",
    "        shap_stddev = shap_values.std(0)[:-1].mean()\n",
    "\n",
    "#         print(\"mean std dev of SHAP values over samples:\", shap_stddev)\n",
    "\n",
    "        e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "        nsamples = 200\n",
    "#         print(shap_stddev/20)\n",
    "        for j in range(2000):\n",
    "            #print(nsamples)\n",
    "            start = time.time()\n",
    "            std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "            iter_time = (time.time() - start)/50\n",
    "            #print(std_dev)\n",
    "            if std_dev < shap_stddev/20:\n",
    "#                 print(\"KernelExplainer\", nsamples)\n",
    "#                 print(\"KernelExplainer\", std_dev)\n",
    "#                 print(\"KernelExplainer\", iter_time, \"seconds\")\n",
    "                kernel_shap_time += iter_time * 1000\n",
    "                break\n",
    "            nsamples += int(nsamples * 0.5)\n",
    "\n",
    "        e = IMEExplainer(f, X.mean(0).reshape(1,M))\n",
    "        nsamples = 200\n",
    "        for j in range(2000):\n",
    "        #     print()\n",
    "        #     print(nsamples)\n",
    "            start = time.time()\n",
    "            std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "        #     print(\"time\", (time.time() - start)/50)\n",
    "        #     print(std_dev)\n",
    "            iter_time = (time.time() - start)/50\n",
    "            if std_dev < shap_stddev/20:\n",
    "#                 print(\"IMEExplainer\", nsamples)\n",
    "#                 print(\"IMEExplainer\", std_dev)\n",
    "#                 print(\"IMEExplainer\", iter_time, \"seconds\")\n",
    "                ime_time += iter_time * 1000\n",
    "                break\n",
    "            nsamples += int(nsamples * 0.5)\n",
    "\n",
    "    tree_shap_times.append(tree_shap_time / nreps)\n",
    "    kernel_shap_times.append(kernel_shap_time / nreps)\n",
    "    ime_times.append(ime_time / nreps)\n",
    "    print(\"TreeExplainer\", tree_shap_times[-1])\n",
    "    print(\"KernelExplainer\", kernel_shap_times[-1])\n",
    "    print(\"IMEExplainer\", ime_times[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(xgboost.DMatrix(X)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.TreeExplainer(model).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=100) for i in range(50)]).std(0)[:-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "nsamples = 200\n",
    "print(shap_stddev/20)\n",
    "for j in range(2000):\n",
    "    print(nsamples)\n",
    "    start = time.time()\n",
    "    std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "    iter_time = time.time() - start)/50\n",
    "    print(std_dev)\n",
    "    if std_dev < shap_stddev/20:\n",
    "        print(nsamples)\n",
    "        break\n",
    "    nsamples += int(nsamples * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = IMEExplainer(f, X.mean(0).reshape(1,M))\n",
    "nsamples = 200\n",
    "print(shap_stddev/20)\n",
    "for j in range(2000):\n",
    "    print()\n",
    "    print(nsamples)\n",
    "    start = time.time()\n",
    "    std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "    print(\"time\", (time.time() - start)/50)\n",
    "    print(std_dev)\n",
    "    if std_dev < shap_stddev/20:\n",
    "        print(nsamples)\n",
    "        break\n",
    "    nsamples += int(nsamples * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.56939 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([IMEExplainer(f, X.mean(0).reshape(1,M)).shap_values(X[:1,:], silent=True, nsamples=1000)[0,0] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[shap.KernelExplainer(f, X.mean(0).reshape(1,M)).shap_values(X[:1,:], silent=True, nsamples=1000)[0,0] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return model.predict(xgboost.DMatrix(x))\n",
    "\n",
    "start = time.time()\n",
    "shap_values2 = shap.KernelExplainer(f, X.mean(0).reshape(1,M)).shap_values(X)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "IMEExplainer(f, X.mean(0).reshape(1,M)).shap_values(X)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

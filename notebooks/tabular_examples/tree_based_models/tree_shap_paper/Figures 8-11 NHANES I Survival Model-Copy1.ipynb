{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 8-11 NHANES I Survival Model\n",
    "\n",
    "This is a cox proportional hazards model on data from <a href=\"https://wwwn.cdc.gov/nchs/nhanes/nhanes1\">NHANES I</a> with followup mortality data from the <a href=\"https://wwwn.cdc.gov/nchs/nhanes/nhefs\">NHANES I Epidemiologic Followup Study</a>. It is designed to illustrate how through the use of SHAP values we can interpret XGBoost models where traditionally only linear models are used. We see interesting and non-linear patterns in the data, which suggest the potential of this approach. Keep in mind the data has not yet been checked by us for calibrations to current lab tests and so you should not consider this as rock solid medical insights, but rather just as a proof of concept. \n",
    "\n",
    "Note that XGBoost only recently got support for a Cox objective, so you will need the most recent version of master."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import shap\n",
    "import scipy as sp\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create XGBoost data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.nhanesi()\n",
    "X_display,y_display = shap.datasets.nhanesi(display=True)\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "def sort_data(X, y):\n",
    "    sinds = np.argsort(np.abs(y))\n",
    "    return X.iloc[sinds,:],y[sinds]\n",
    "\n",
    "# create a complete dataset\n",
    "#X,y = sort_data(X, np.array(y))\n",
    "xgb_full = xgboost.DMatrix(X.as_matrix(), label=y)\n",
    "\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "#X_train,y_train = sort_data(X_train, y_train)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "#X_test,y_test = sort_data(X_test, y_test)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.diabetes()\n",
    "xgb_full = xgboost.DMatrix(X.as_matrix(), label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on the full data set\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 3, \n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "model = xgboost.train(params, xgb_full, 700, evals = [(xgb_full, \"test\")], verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on the full data set\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1, \n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "model = xgboost.cv(params, xgboost.DMatrix(Xm, y), 1000, verbose_eval=100)\n",
    "model = xgboost.train(params, xgboost.DMatrix(Xm, y), 300, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values2 = shap.TreeExplainer(model).shap_values(Xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(Xm[:,8], y, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(8, shap_values2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    shap.dependence_plot(i, shap_values2, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use validation set to choose # of trees\n",
    "# params = {\n",
    "#     \"eta\": 0.001,\n",
    "#     \"max_depth\": 3,\n",
    "#     \"objective\": \"survival:cox\",\n",
    "#     \"subsample\": 0.5\n",
    "# }\n",
    "# model_train = xgboost.train(params, xgb_train, 10000, evals = [(xgb_test, \"test\")], verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on the full data set\n",
    "params = {\n",
    "    \"eta\": 0.001,\n",
    "    \"max_depth\": 3, \n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "model = xgboost.train(params, xgb_full, 7000, evals = [(xgb_full, \"test\")], verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the predictions on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "shap_values = model.predict(xgb_full, pred_contribs=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return model.predict(xgboost.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?shap.force_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(xgboost.DMatrix(np.zeros((1,X.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(f, np.zeros((1,X.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(f, X.median().as_matrix()[inds[:10],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "explainer = shap.KernelExplainer(f, X.as_matrix()[inds[:10],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6 * X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "inds = np.arange(X.shape[1])\n",
    "np.random.shuffle(inds)\n",
    "np.where(inds == j)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(0, 10, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ime(j, f, x, X, nsamples=10):\n",
    "    assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "    \n",
    "    X_masked = np.zeros((nsamples, X.shape[1]))\n",
    "    inds = np.arange(X.shape[1])\n",
    "    \n",
    "    for i in range(0, nsamples//2):\n",
    "        pos = np.where(inds == j)[0][0]\n",
    "        rind = np.random.randint(X.shape[0])\n",
    "        X_masked[i,:] = x\n",
    "        X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "#         print(i)\n",
    "#         print(-(i+1))\n",
    "        X_masked[-(i+1),:] = x\n",
    "        X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "#     print(X_masked)\n",
    "    evals = f(X_masked)\n",
    "    return np.mean(evals[:nsamples//2] - evals[nsamples//2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iml.common import convert_to_instance, convert_to_model, match_instance_to_data, match_model_to_data, convert_to_instance_with_index\n",
    "from iml.explanations import AdditiveExplanation\n",
    "from iml.links import convert_to_link, IdentityLink\n",
    "from iml.datatypes import convert_to_data, DenseData\n",
    "import logging\n",
    "from iml.explanations import AdditiveExplanation\n",
    "\n",
    "log = logging.getLogger('shap')\n",
    "from shap import KernelExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap import KernelExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMEExplainer(KernelExplainer):\n",
    "    \"\"\" This is an implementation of the IME explanation method (aka. Shapley sampling values)\n",
    "    \n",
    "    This is implemented here for comparision and evaluation purposes, the KernelExplainer is\n",
    "    typically more efficient and so is the preferred model agnostic estimation method in this package.\n",
    "    IME was proposed in \"An Efficient Explanation of Individual Classifications using Game Theory\",\n",
    "    Erik Štrumbelj, Igor Kononenko, JMLR 2010\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        # silence warning about large datasets\n",
    "        level = log.level\n",
    "        log.setLevel(logging.ERROR)\n",
    "        super(IMEExplainer, self).__init__(model, data, **kwargs)\n",
    "        log.setLevel(level)\n",
    "    \n",
    "    def explain(self, incoming_instance, **kwargs):\n",
    "        # convert incoming input to a standardized iml object\n",
    "        instance = convert_to_instance(incoming_instance)\n",
    "        match_instance_to_data(instance, self.data)\n",
    "        \n",
    "        # pick a reasonable number of samples if the user didn't specify how many they wanted\n",
    "        self.nsamples = kwargs.get(\"nsamples\", 0)\n",
    "        if self.nsamples == 0:\n",
    "            self.nsamples = 1000 * self.P\n",
    "        \n",
    "        # divide up the samples among the features\n",
    "        self.nsamples_each = np.ones(self.P, dtype=np.int64) * 2 * (self.nsamples // (self.P * 2))\n",
    "        for i in range((self.nsamples % (self.P * 2)) // 2):\n",
    "            self.nsamples_each[i] += 2\n",
    "        \n",
    "        model_out = self.model.f(instance.x)\n",
    "        \n",
    "        # explain every feature\n",
    "        phi = np.zeros(self.P)\n",
    "        self.X_masked = np.zeros((self.nsamples_each.max(), X.shape[1]))\n",
    "        for i in range(self.P):\n",
    "            phi[i] = self.ime(i, self.model.f, instance.x, self.data.data, nsamples=self.nsamples_each[i])\n",
    "        phi = np.array(phi)\n",
    "        \n",
    "        return AdditiveExplanation(self.link.f(1), self.link.f(1), phi, np.zeros(len(phi)), instance, self.link,\n",
    "                                   self.model, self.data)\n",
    "        \n",
    "        \n",
    "    def ime(self, j, f, x, X, nsamples=10):\n",
    "        assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "#         print(\"nsamples\", nsamples, j)\n",
    "        X_masked = self.X_masked[:nsamples,:]\n",
    "        inds = np.arange(X.shape[1])\n",
    "\n",
    "        for i in range(0, nsamples//2):\n",
    "            np.random.shuffle(inds)\n",
    "            pos = np.where(inds == j)[0][0]\n",
    "            rind = np.random.randint(X.shape[0])\n",
    "            X_masked[i,:] = x\n",
    "            X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "            X_masked[-(i+1),:] = x\n",
    "            X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "            \n",
    "        evals = f(X_masked)\n",
    "        \n",
    "        evals_on = evals[:nsamples//2]\n",
    "        evals_off = evals[nsamples//2:][::-1]\n",
    "#         if j == 0:\n",
    "#             print(evals)\n",
    "#             print(np.vstack((X_masked[:,0], evals)).T)\n",
    "#             print(np.mean(evals[:nsamples//2] - evals[nsamples//2:]))\n",
    "#             print(evals_on - evals_off)\n",
    "        return np.mean(evals[:nsamples//2] - evals[nsamples//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleExplainer(KernelExplainer):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        # silence warning about large datasets\n",
    "        level = log.level\n",
    "        log.setLevel(logging.ERROR)\n",
    "        super(SampleExplainer, self).__init__(model, data, **kwargs)\n",
    "        log.setLevel(level)\n",
    "        \n",
    "        self.model_null = np.mean(self.model.f(self.data.data))\n",
    "    \n",
    "    def explain(self, incoming_instance, **kwargs):\n",
    "        # convert incoming input to a standardized iml object\n",
    "        instance = convert_to_instance(incoming_instance)\n",
    "        match_instance_to_data(instance, self.data)\n",
    "        \n",
    "        # pick a reasonable number of samples if the user didn't specify how many they wanted\n",
    "        self.nsamples = kwargs.get(\"nsamples\", 0)\n",
    "        if self.nsamples == 0:\n",
    "            self.nsamples = 1000 * self.P\n",
    "        \n",
    "        model_out = self.model.f(instance.x)\n",
    "        \n",
    "        # explain every instance\n",
    "        phi = np.zeros(self.P)\n",
    "        self.X_masked = np.zeros((self.nsamples, X.shape[1]))\n",
    "        self.X_mask = np.zeros((self.nsamples+1, X.shape[1]))\n",
    "        #print(instance.x)\n",
    "        size_weights = np.array([(self.P - 1)/(s * (self.P - s)) for s in range(1,self.P)])\n",
    "        size_weights /= size_weights.sum()\n",
    "        for i in range(self.nsamples):\n",
    "            # choose size of the subset\n",
    "            s = np.random.choice(len(size_weights), 1, p=size_weights) + 1\n",
    "\n",
    "            # choose subset\n",
    "            S = np.random.choice(M, s, replace=False)\n",
    "\n",
    "            rind = np.random.randint(self.data.data.shape[0])\n",
    "            #print(rind)\n",
    "            self.X_masked[i,:] = self.data.data[rind,:]\n",
    "            self.X_masked[i,S] = instance.x[0,S]\n",
    "            self.X_mask[i,S] = 1\n",
    "        \n",
    "        y = np.zeros(self.nsamples+1)\n",
    "        y[:-1] = self.model.f(self.X_masked)\n",
    "        self.X_mask[-1,:] = 1\n",
    "        y[-1] = self.model.f(instance.x)[0]\n",
    "        y -= self.model_null\n",
    "        #print(y)\n",
    "        weights = np.ones(self.nsamples + 1) / (self.nsamples * 100)\n",
    "        weights[-1] = 0.99\n",
    "        #print(weights.sum())\n",
    "        \n",
    "        tmp = (self.X_mask.T * weights)\n",
    "        phi = np.linalg.inv(tmp @ self.X_mask + np.eye(self.P) * 0.01 / self.nsamples) @ tmp @ y\n",
    "        #print(phi.sum())\n",
    "        #print(\"self.model_null\", self.model_null)\n",
    "        #print(phi)\n",
    "        return AdditiveExplanation(self.link.f(1), self.link.f(1), phi, np.zeros(len(phi)), instance, self.link,\n",
    "                                   self.model, self.data)\n",
    "        \n",
    "        \n",
    "#     def ime(self, j, f, x, X, nsamples=10):\n",
    "#         assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "# #         print(\"nsamples\", nsamples, j)\n",
    "#         X_masked = self.X_masked[:nsamples,:]\n",
    "#         inds = np.arange(X.shape[1])\n",
    "\n",
    "#         for i in range(0, nsamples//2):\n",
    "#             np.random.shuffle(inds)\n",
    "#             pos = np.where(inds == j)[0][0]\n",
    "#             rind = np.random.randint(X.shape[0])\n",
    "#             X_masked[i,:] = x\n",
    "#             X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "#             X_masked[-(i+1),:] = x\n",
    "#             X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "            \n",
    "#         evals = f(X_masked)\n",
    "        \n",
    "#         evals_on = evals[:nsamples//2]\n",
    "#         evals_off = evals[nsamples//2:][::-1]\n",
    "# #         if j == 0:\n",
    "# #             print(evals)\n",
    "# #             print(np.vstack((X_masked[:,0], evals)).T)\n",
    "# #             print(np.mean(evals[:nsamples//2] - evals[nsamples//2:]))\n",
    "# #             print(evals_on - evals_off)\n",
    "#         return np.mean(evals[:nsamples//2] - evals[nsamples//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleExplainer2(KernelExplainer):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        # silence warning about large datasets\n",
    "        level = log.level\n",
    "        log.setLevel(logging.ERROR)\n",
    "        super(SampleExplainer, self).__init__(model, data, **kwargs)\n",
    "        log.setLevel(level)\n",
    "        \n",
    "        self.model_null = np.mean(self.model.f(self.data.data))\n",
    "    \n",
    "    def explain(self, incoming_instance, **kwargs):\n",
    "        # convert incoming input to a standardized iml object\n",
    "        instance = convert_to_instance(incoming_instance)\n",
    "        match_instance_to_data(instance, self.data)\n",
    "        \n",
    "        # pick a reasonable number of samples if the user didn't specify how many they wanted\n",
    "        self.nsamples = kwargs.get(\"nsamples\", 0)\n",
    "        if self.nsamples == 0:\n",
    "            self.nsamples = 1000 * self.P\n",
    "        \n",
    "        model_out = self.model.f(instance.x)\n",
    "        \n",
    "        # explain every instance\n",
    "        phi = np.zeros(self.P)\n",
    "        self.X_masked = np.zeros((self.nsamples, X.shape[1]))\n",
    "        self.X_mask = np.zeros((self.nsamples+1, X.shape[1]))\n",
    "        #print(instance.x)\n",
    "        size_weights = np.array([(self.P - 1)/(s * (self.P - s)) for s in range(1,self.P)])\n",
    "        size_weights /= size_weights.sum()\n",
    "        for i in range(self.nsamples):\n",
    "            # choose size of the subset\n",
    "            s = np.random.choice(len(size_weights), 1, p=size_weights) + 1\n",
    "\n",
    "            # choose subset\n",
    "            S = np.random.choice(M, s, replace=False)\n",
    "\n",
    "            rind = np.random.randint(self.data.data.shape[0])\n",
    "            #print(rind)\n",
    "            self.X_masked[i,:] = self.data.data[rind,:]\n",
    "            self.X_masked[i,S] = instance.x[0,S]\n",
    "            self.X_mask[i,S] = 1\n",
    "        \n",
    "        y = np.zeros(self.nsamples+1)\n",
    "        y[:-1] = self.model.f(self.X_masked)\n",
    "        self.X_mask[-1,:] = 1\n",
    "        y[-1] = self.model.f(instance.x)[0]\n",
    "        y -= self.model_null\n",
    "        #print(y)\n",
    "        weights = np.ones(self.nsamples + 1) / (self.nsamples * 100)\n",
    "        weights[-1] = 0.99\n",
    "        #print(weights.sum())\n",
    "        \n",
    "        tmp = (self.X_mask.T * weights)\n",
    "        phi = np.linalg.inv(tmp @ self.X_mask + np.eye(self.P) * 0.01 / self.nsamples) @ tmp @ y\n",
    "        #print(phi.sum())\n",
    "        #print(\"self.model_null\", self.model_null)\n",
    "        #print(phi)\n",
    "        return AdditiveExplanation(self.link.f(1), self.link.f(1), phi, np.zeros(len(phi)), instance, self.link,\n",
    "                                   self.model, self.data)\n",
    "        \n",
    "        \n",
    "#     def ime(self, j, f, x, X, nsamples=10):\n",
    "#         assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "# #         print(\"nsamples\", nsamples, j)\n",
    "#         X_masked = self.X_masked[:nsamples,:]\n",
    "#         inds = np.arange(X.shape[1])\n",
    "\n",
    "#         for i in range(0, nsamples//2):\n",
    "#             np.random.shuffle(inds)\n",
    "#             pos = np.where(inds == j)[0][0]\n",
    "#             rind = np.random.randint(X.shape[0])\n",
    "#             X_masked[i,:] = x\n",
    "#             X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "#             X_masked[-(i+1),:] = x\n",
    "#             X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "            \n",
    "#         evals = f(X_masked)\n",
    "        \n",
    "#         evals_on = evals[:nsamples//2]\n",
    "#         evals_off = evals[nsamples//2:][::-1]\n",
    "# #         if j == 0:\n",
    "# #             print(evals)\n",
    "# #             print(np.vstack((X_masked[:,0], evals)).T)\n",
    "# #             print(np.mean(evals[:nsamples//2] - evals[nsamples//2:]))\n",
    "# #             print(evals_on - evals_off)\n",
    "#         return np.mean(evals[:nsamples//2] - evals[nsamples//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = KernelExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    phi1 = SampleExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000)\n",
    "    phi2 = IMEExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000//2)\n",
    "#     print(\"phi1\", phi1)\n",
    "#     print(\"phi2\", phi2)\n",
    "    \n",
    "#     print(\"correct\", correct)\n",
    "    print(np.abs(correct[:-1] - phi1[:-1]).sum())\n",
    "    print(np.abs(correct[:-1] - phi2[:-1]).sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[IMEExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMEExplainer(f, Xm).shap_values(Xm[0,:], nsamples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.TreeExplainer(model).shap_values(Xm[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.KernelExplainer(model).shap_values(Xm[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([SampleExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([IMEExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 1000)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(M - 1)/(s * (M - s)) for s in range(M+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = X.shape[1]\n",
    "size_weights = np.array([(M - 1)/(s * (M - s)) for s in range(1,M)])\n",
    "size_weights /= size_weights.sum()\n",
    "for i in range(10):\n",
    "    # choose size of the subset\n",
    "    s = np.random.choice(len(size_weights), 1, p=size_weights) + 1\n",
    "    \n",
    "    # choose subset\n",
    "    S = np.random.choice(M, s, replace=False)\n",
    "    \n",
    "    rind = np.random.randint(X.shape[0]\n",
    "    \n",
    "    print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(size_weights),M\n",
    "\n",
    "M = \n",
    "size_weights = np.array([(M - 1)/(s * (M - s)) for s in range(1,M)])\n",
    "\n",
    "[0, 1, 2, 2.75, 3.33, 3.80555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M = 3\n",
    "(M - 1)/(M-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([IMEExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 100)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([IMEExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 100)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([IMEExplainer(f, Xm).shap_values(Xm[0,:], nsamples = 1000)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([SampleExplainer(f, Xm).shap_values(Xm[0,:], nsamples = 1000)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "n_iter = 100\n",
    "dist_kernel = np.zeros(n_iter)\n",
    "for i in range(n_iter):\n",
    "    np.random.shuffle(inds)\n",
    "    dist_kernel[i] = KernelExplainer(f, Xm[inds[10:20],:]).shap_values(Xm[0,:], nsamples = 1000)[0]\n",
    "dist_kernel.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "n_iter = 100\n",
    "dist_kernel = np.zeros(n_iter)\n",
    "for i in range(n_iter):\n",
    "    np.random.shuffle(inds)\n",
    "    dist_kernel[i] = KernelExplainer(f, Xm[inds[10:20],:]).shap_values(Xm[0,:], nsamples = 1000)[0]\n",
    "dist_kernel.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "n_iter = 100\n",
    "dist_kernel = np.zeros(n_iter)\n",
    "for i in range(n_iter):\n",
    "    #np.random.shuffle(inds)\n",
    "    dist_kernel[i] = KernelExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 100)[0]\n",
    "dist_kernel.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "n_iter = 100\n",
    "dist_kernel = np.zeros(n_iter)\n",
    "for i in range(n_iter):\n",
    "    np.random.shuffle(inds)\n",
    "    for j in range(10):\n",
    "        dist_kernel[i] += KernelExplainer(f, Xm[inds[0]:inds[0]+1,:]).shap_values(Xm[0,:], nsamples = 100)[0]\n",
    "    dist_kernel[i] /= j\n",
    "dist_kernel.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "n_iter = 100\n",
    "dist_kernel = np.zeros(n_iter)\n",
    "for i in range(n_iter):\n",
    "    #np.random.shuffle(inds)\n",
    "    for j in range(10):\n",
    "        dist_kernel[i] += IMEExplainer(f, Xm[inds[0]:inds[0]+1,:]).shap_values(Xm[0,:], nsamples = 100)[0]\n",
    "    dist_kernel[i] /= j\n",
    "dist_kernel.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ime = np.array([IMEExplainer(f, np.zeros((1,X.shape[1]))).shap_values(Xm[0,:], nsamples = 100)[0] for i in range(100)])\n",
    "dist_ime.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(dist)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = f(X.as_matrix())\n",
    "\n",
    "np.linalg.inv(X.as_matrix().T @ X.as_matrix()) @ X.as_matrix().T @ (y - y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = f(X.as_matrix())\n",
    "\n",
    "Xm = X.as_matrix()\n",
    "np.linalg.inv(Xm.T @ Xm) @ Xm.T @ (y - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(Xm.T @ Xm) @ Xm.T @ np.ones(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = f(X.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(Xm[:,0], y, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    pl.plot(Xm[:,i], y, \".\")\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(0, shap_values, X, interaction_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(X.iloc[:,0])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    pl.hist(X.iloc[:,i])\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.kmeans(X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.KernelExplainer(f, X).shap_values(X.iloc[0:1,:], nsamples=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.KernelExplainer(f, shap.kmeans(X, 5)).shap_values(X.iloc[0:1,:], nsamples=10040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "np.random.shuffle(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "phi = np.zeros(X.shape[1]+1)\n",
    "for i in range(1):\n",
    "    np.random.shuffle(inds)\n",
    "    phi += shap.KernelExplainer(f, X.iloc[inds[:1000],:]).shap_values(X.iloc[0,:], nsamples=10000)\n",
    "phi / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(X.shape[0])\n",
    "phi = np.zeros(X.shape[1]+1)\n",
    "for i in range(1000):\n",
    "    np.random.shuffle(inds)\n",
    "    phi += shap.KernelExplainer(f, X.iloc[inds[:1],:]).shap_values(X.iloc[0,:], nsamples=10000)\n",
    "phi / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.KernelExplainer(f, X.iloc[inds[:1000],:]).shap_values(X.iloc[0:1,:], nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[ime(j, f, X.as_matrix()[0,:], X.as_matrix(), nsamples=1000) for j in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, show=False)\n",
    "pl.savefig(\"data/nhanes_summary.pdf\", dpi=400)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values, X, show=False)\n",
    "# pl.gca().set_rasterized(True)\n",
    "# pl.savefig(\"data/nhanes_summary.pdf\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"BMI\", shap_values, X, show=False, interaction_index=\"BMI\")\n",
    "pl.xlim(15,50)\n",
    "pl.gcf().set_size_inches(5.5, 5)\n",
    "#pl.savefig(\"data/nhanes_bmi.pdf\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Systolic BP\", shap_values, X, show=False)\n",
    "pl.xlim(80,225)\n",
    "pl.ylim(-0.4,0.8)\n",
    "pl.savefig(\"data/nhanes_sbp.pdf\", dpi=400)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Pulse pressure\", shap_values, X, show=False)\n",
    "#pl.xlim(80,225)\n",
    "# pl.savefig(\"data/nhanes_sbp.pdf\")\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SHAP Interaction Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "shap_interaction_values = model.predict(xgboost.DMatrix(X.iloc[:,:]), pred_interactions=True)\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMEExplainer:\n",
    "    \"\"\" This is an implementation of the IME explanation method (aka. Shapley sampling values)\n",
    "    \n",
    "    This is implemented here for comparision and evaluation purposes, the KernelExplainer is more\n",
    "    typically more efficient and so is the preferred model agnostic estimation method in this package.\n",
    "    IME was proposed in \"An Efficient Explanation of Individual Classifications using Game Theory\",\n",
    "    Erik Štrumbelj, Igor Kononenko, JMLR 2010\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        self.model = convert_to_model(model)\n",
    "        self.keep_index = kwargs.get(\"keep_index\", False)\n",
    "        self.data = convert_to_data(data, keep_index=self.keep_index)\n",
    "        match_model_to_data(self.model, self.data)\n",
    "        \n",
    "        # enforce our current input type limitations\n",
    "        assert isinstance(self.data, DenseData), \"Shap explainer only supports the DenseData input currently.\"\n",
    "        assert not self.data.transposed, \"Shap explainer does not support transposed DenseData currently.\"\n",
    "\n",
    "        # init our parameters\n",
    "        self.N = self.data.data.shape[0]\n",
    "        self.P = self.data.data.shape[1]\n",
    "        self.nsamplesAdded = 0\n",
    "        self.nsamplesRun = 0\n",
    "        \n",
    "    def shap_values(self, X, **kwargs):\n",
    "        # convert dataframes\n",
    "        if str(type(X)).endswith(\"pandas.core.series.Series'>\"):\n",
    "            X = X.as_matrix()\n",
    "        elif str(type(X)).endswith(\"'pandas.core.frame.DataFrame'>\"):\n",
    "            if self.keep_index:\n",
    "                index_value = X.index.values\n",
    "                index_name = X.index.name\n",
    "                column_name = list(X.columns)\n",
    "            X = X.as_matrix()\n",
    "\n",
    "        assert str(type(X)).endswith(\"'numpy.ndarray'>\"), \"Unknown instance type: \" + str(type(X))\n",
    "        assert len(X.shape) == 1 or len(X.shape) == 2, \"Instance must have 1 or 2 dimensions!\"\n",
    "        \n",
    "        # pick a reasonable number of samples if the user didn't specify how many they wanted\n",
    "        nsamples = kwargs.get(\"nsamples\", 0)\n",
    "        if nsamples == 0:\n",
    "            nsamples = 1000 * self.P\n",
    "        \n",
    "        # divide up the samples among the features\n",
    "        nsamples_each = np.ones(self.P) * 2 * (nsamples // (self.P * 2))\n",
    "        for i in range((nsamples % (self.P * 2)) // 2):\n",
    "            nsamples_each[i] += 2\n",
    "        \n",
    "        # single instance\n",
    "        if len(X.shape) == 1:\n",
    "            data = X.reshape((1, X.shape[0]))\n",
    "            if self.keep_index:\n",
    "                data = convert_to_instance_with_index(data, column_name, index_name, index_value)\n",
    "            explanation = self.explain(data, **kwargs)\n",
    "\n",
    "            # vector-output\n",
    "            s = explanation.effects.shape\n",
    "            if len(s) == 2:\n",
    "                outs = [np.zeros(s[0] + 1) for j in range(s[1])]\n",
    "                for j in range(s[1]):\n",
    "                    outs[j][:-1] = explanation.effects[:, j]\n",
    "                    outs[j][-1] = explanation.base_value[j]\n",
    "                return outs\n",
    "\n",
    "            # single-output\n",
    "            else:\n",
    "                out = np.zeros(s[0] + 1)\n",
    "                out[:-1] = explanation.effects\n",
    "                out[-1] = explanation.base_value\n",
    "                return out\n",
    "\n",
    "        # explain the whole dataset\n",
    "        elif len(X.shape) == 2:\n",
    "            explanations = []\n",
    "            for i in tqdm(range(X.shape[0])):\n",
    "                data = X[i:i + 1, :]\n",
    "                if self.keep_index:\n",
    "                    data = convert_to_instance_with_index(data, column_name, index_value[i:i + 1], index_name)\n",
    "                explanations.append(self.explain(data, **kwargs))\n",
    "\n",
    "            # vector-output\n",
    "            s = explanations[0].effects.shape\n",
    "            if len(s) == 2:\n",
    "                outs = [np.zeros((X.shape[0], s[0] + 1)) for j in range(s[1])]\n",
    "                for i in range(X.shape[0]):\n",
    "                    for j in range(s[1]):\n",
    "                        outs[j][i, :-1] = explanations[i].effects[:, j]\n",
    "                        outs[j][i, -1] = explanations[i].base_value[j]\n",
    "                return outs\n",
    "\n",
    "            # single-output\n",
    "            else:\n",
    "                out = np.zeros((X.shape[0], s[0] + 1))\n",
    "                for i in range(X.shape[0]):\n",
    "                    out[i, :-1] = explanations[i].effects\n",
    "                    out[i, -1] = explanations[i].base_value\n",
    "                return out\n",
    "        \n",
    "        \n",
    "    def ime(j, f, x, X, nsamples=10):\n",
    "        assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "\n",
    "        X_masked = np.zeros((nsamples, X.shape[1]))\n",
    "        inds = np.arange(X.shape[1])\n",
    "\n",
    "        for i in range(0, nsamples//2):\n",
    "            pos = np.where(inds == j)[0][0]\n",
    "            rind = np.random.randint(X.shape[0])\n",
    "            X_masked[i,:] = x\n",
    "            X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "    #         print(i)\n",
    "    #         print(-(i+1))\n",
    "            X_masked[-(i+1),:] = x\n",
    "            X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "    #     print(X_masked)\n",
    "        evals = f(X_masked)\n",
    "        return np.mean(evals[:nsamples//2] - evals[nsamples//2:])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(pred[i]),np.exp(pred[i:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xgb_full, output_margin=True)\n",
    "pred = np.flip(np.sort(pred),axis=0)\n",
    "C = 0.001\n",
    "tmp = [np.log(np.exp(pred[i]+C)/(np.exp(pred[i+1:]).sum() + np.exp(pred[i]+C))) - np.log(np.exp(pred[i])/np.exp(pred[i:]).sum()) for i in range(1000)]\n",
    "pl.plot(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled(A, B, C):\n",
    "    return A*C/(B + A*C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 100\n",
    "C = 0.01\n",
    "out = np.zeros(100)\n",
    "proportion = np.zeros(100)\n",
    "As = np.linspace(-20,20,100)\n",
    "for i,A in enumerate(As):\n",
    "    proportion[i] = np.exp(A)/(B+np.exp(A))\n",
    "    out[i] = A + C - np.log(B + np.exp(A)*np.exp(C)) - (A - np.log(B + np.exp(A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(proportion,out)\n",
    "pl.title(\"Asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-10,10,100)\n",
    "pl.plot(xs, np.log(1/(1+np.exp(-xs+C))) - np.log(1/(1+np.exp(-xs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1) - np.log(1+np.exp(-xs+C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    (\"Systolic BP\", \"Systolic BP\"),\n",
    "    shap_interaction_values, X.iloc[:,:],\n",
    "    display_features=X_display.iloc[:,:],\n",
    "    show=False\n",
    ")\n",
    "pl.xlim(80,225)\n",
    "pl.ylim(-0.4,0.8)\n",
    "pl.ylabel(\"SHAP main effect value for\\nSystolic BP\")\n",
    "pl.gcf().set_size_inches(6, 5)\n",
    "pl.savefig(\"data/nhanes_sbp_main_effect.pdf\", dpi=400)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependence_plot2(ind, shap_values, features, feature_names=None, display_features=None,\n",
    "                    interaction_index=\"auto\", color=\"#ff0052\", axis_color=\"#333333\",\n",
    "                    dot_size=16, alpha=1, title=None, show=True):\n",
    "    \"\"\"\n",
    "    Create a SHAP dependence plot, colored by an interaction feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ind : int\n",
    "        Index of the feature to plot.\n",
    "\n",
    "    shap_values : numpy.array\n",
    "        Matrix of SHAP values (# samples x # features)\n",
    "\n",
    "    features : numpy.array or pandas.DataFrame\n",
    "        Matrix of feature values (# samples x # features)\n",
    "\n",
    "    feature_names : list\n",
    "        Names of the features (length # features)\n",
    "\n",
    "    display_features : numpy.array or pandas.DataFrame\n",
    "        Matrix of feature values for visual display (such as strings instead of coded values)\n",
    "\n",
    "    interaction_index : \"auto\", None, or int\n",
    "        The index of the feature used to color the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert from DataFrames if we got any\n",
    "    if str(type(features)) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "        if feature_names is None:\n",
    "            feature_names = features.columns\n",
    "        features = features.as_matrix()\n",
    "    if str(type(display_features)) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "        if feature_names is None:\n",
    "            feature_names = display_features.columns\n",
    "        display_features = display_features.as_matrix()\n",
    "    elif display_features is None:\n",
    "        display_features = features\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [\"Feature \"+str(i) for i in range(shap_values.shape[1]-1)]\n",
    "\n",
    "    # allow vectors to be passed\n",
    "    if len(shap_values.shape) == 1:\n",
    "        shap_values = np.reshape(shap_values, len(shap_values), 1)\n",
    "    if len(features.shape) == 1:\n",
    "        features = np.reshape(features, len(features), 1)\n",
    "\n",
    "    def convert_name(ind):\n",
    "        if type(ind) == str:\n",
    "            nzinds = np.where(feature_names == ind)[0]\n",
    "            if len(nzinds) == 0:\n",
    "                print(\"Could not find feature named: \"+ind)\n",
    "                return None\n",
    "            else:\n",
    "                return nzinds[0]\n",
    "        else:\n",
    "            return ind\n",
    "\n",
    "    ind = convert_name(ind)\n",
    "\n",
    "    # plotting SHAP interaction values\n",
    "    if len(shap_values.shape) == 3 and len(ind) == 2:\n",
    "        ind1 = convert_name(ind[0])\n",
    "        ind2 = convert_name(ind[1])\n",
    "        if ind1 == ind2:\n",
    "            proj_shap_values = shap_values[:,ind2,:]\n",
    "        else:\n",
    "            proj_shap_values = shap_values[:,ind2,:] * 2 # off-diag values are split in half\n",
    "        dependence_plot2(\n",
    "            ind1, proj_shap_values, features, feature_names=feature_names,\n",
    "            interaction_index=ind2, display_features=display_features, show=False\n",
    "        )\n",
    "        if ind1 == ind2:\n",
    "            pl.ylabel(\"SHAP main effect value for\\n\"+feature_names[ind1])\n",
    "        else:\n",
    "            pl.ylabel(\"SHAP interaction value for\\n\"+feature_names[ind1]+\" and \"+feature_names[ind2])\n",
    "\n",
    "        if show:\n",
    "            pl.show()\n",
    "        return\n",
    "\n",
    "    # get both the raw and display feature values\n",
    "    xv = features[:,ind]\n",
    "    xd = display_features[:,ind]\n",
    "    s = shap_values[:,ind]\n",
    "    if type(xd[0]) == str:\n",
    "        name_map = {}\n",
    "        for i in range(len(xv)):\n",
    "            name_map[xd[i]] = xv[i]\n",
    "        xnames = list(name_map.keys())\n",
    "\n",
    "    # allow a single feature name to be passed alone\n",
    "    if type(feature_names) == str:\n",
    "        feature_names = [feature_names]\n",
    "    name = feature_names[ind]\n",
    "\n",
    "    # guess what other feature as the stongest interaction with the plotted feature\n",
    "    if interaction_index == \"auto\":\n",
    "        interaction_index = approx_interactions(ind, shap_values, features)[0]\n",
    "    interaction_index = convert_name(interaction_index)\n",
    "\n",
    "    # get both the raw and display color values\n",
    "    cv = features[:,interaction_index]\n",
    "    cd = display_features[:,interaction_index]\n",
    "    categorical_interaction = False\n",
    "    clow = np.nanpercentile(features[:,interaction_index], 5)\n",
    "    chigh = np.nanpercentile(features[:,interaction_index], 95)\n",
    "    if type(cd[0]) == str:\n",
    "        cname_map = {}\n",
    "        for i in range(len(cv)):\n",
    "            cname_map[cd[i]] = cv[i]\n",
    "        cnames = list(cname_map.keys())\n",
    "        categorical_interaction = True\n",
    "    elif clow % 1 == 0 and chigh % 1 == 0 and len(set(features[:,interaction_index])) < 50:\n",
    "        categorical_interaction = True\n",
    "\n",
    "    # discritize colors for categorical features\n",
    "    color_norm = None\n",
    "    if categorical_interaction and clow != chigh:\n",
    "        bounds = np.linspace(clow, chigh, chigh-clow+2)\n",
    "        color_norm = matplotlib.colors.BoundaryNorm(bounds, red_blue.N)\n",
    "\n",
    "    # the actual scatter plot, TODO: adapt the dot_size to the number of data points?\n",
    "    pl.scatter(xv, s, s=dot_size, linewidth=0, c=\"#1E88E5\",\n",
    "               alpha=alpha, rasterized=len(xv) > 500)\n",
    "\n",
    "    if interaction_index != ind:\n",
    "        # draw the color bar\n",
    "        norm = None\n",
    "        if type(cd[0]) == str:\n",
    "            tick_positions = [cname_map[n] for n in cnames]\n",
    "            if len(tick_positions) == 2:\n",
    "                tick_positions[0] -= 0.25\n",
    "                tick_positions[1] += 0.25\n",
    "            cb = pl.colorbar(ticks=tick_positions)\n",
    "            cb.set_ticklabels(cnames)\n",
    "\n",
    "        else:\n",
    "            cb = pl.colorbar()\n",
    "        cb.set_label(feature_names[interaction_index], size=13)\n",
    "        cb.ax.tick_params(labelsize=11)\n",
    "        if categorical_interaction:\n",
    "            cb.ax.tick_params(length=0)\n",
    "        cb.set_alpha(1)\n",
    "        cb.outline.set_visible(False)\n",
    "        bbox = cb.ax.get_window_extent().transformed(pl.gcf().dpi_scale_trans.inverted())\n",
    "        cb.ax.set_aspect((bbox.height-0.7)*20)\n",
    "\n",
    "    # make the plot more readable\n",
    "    if interaction_index != ind:\n",
    "        pl.gcf().set_size_inches(7.5, 5)\n",
    "    else:\n",
    "        pl.gcf().set_size_inches(6, 5)\n",
    "    pl.xlabel(name, color=axis_color, fontsize=13)\n",
    "    pl.ylabel(\"SHAP value for\\n\"+name, color=axis_color, fontsize=13)\n",
    "    if title != None:\n",
    "        pl.title(title, color=axis_color, fontsize=13)\n",
    "    pl.gca().xaxis.set_ticks_position('bottom')\n",
    "    pl.gca().yaxis.set_ticks_position('left')\n",
    "    pl.gca().spines['right'].set_visible(False)\n",
    "    pl.gca().spines['top'].set_visible(False)\n",
    "    pl.gca().tick_params(color=axis_color, labelcolor=axis_color, labelsize=11)\n",
    "    for spine in pl.gca().spines.values():\n",
    "        spine.set_edgecolor(axis_color)\n",
    "    if type(xd[0]) == str:\n",
    "        pl.xticks([name_map[n] for n in xnames], xnames, rotation='vertical', fontsize=11)\n",
    "    if show:\n",
    "        pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependence_plot2(\n",
    "    (\"Systolic BP\", \"Systolic BP\"),\n",
    "    shap_interaction_values, X.iloc[:,:],\n",
    "    display_features=X_display.iloc[:,:],\n",
    "    show=False\n",
    ")\n",
    "pl.xlim(80,225)\n",
    "pl.ylim(-0.4,0.8)\n",
    "pl.ylabel(\"SHAP main effect value for\\nSystolic BP\")\n",
    "pl.gcf().set_size_inches(6, 5)\n",
    "pl.savefig(\"data/nhanes_sbp_main_effect.pdf\", dpi=400)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    (\"Systolic BP\", \"Age\"),\n",
    "    shap_interaction_values, X.iloc[:,:],\n",
    "    display_features=X_display.iloc[:,:],\n",
    "    show=False\n",
    ")\n",
    "pl.xlim(80,225)\n",
    "pl.ylim(-0.4,0.8)\n",
    "pl.savefig(\"data/nhanes_sbp_age_interaction.pdf\", dpi=400)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    (\"Age\", \"Sex\"),\n",
    "    shap_interaction_values, X.iloc[:1000,:],\n",
    "    display_features=X_display.iloc[:1000,:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(0, shap_interaction_values[:,4,:], X.iloc[:1000,:], interaction_index=4, show=False)\n",
    "pl.ylabel(\"SHAP interaction value for\\nAge and Serum Cholesterol\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(4, shap_interaction_values[:,0,:], X.iloc[:1000,:], interaction_index=0, show=False)\n",
    "pl.ylabel(\"SHAP interaction value for\\nAge and Serum Cholesterol\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "shap_pca2 = PCA(n_components=2).fit_transform(shap_values[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_pca2[:,0], shap_pca2[:,1], c=np.sum(shap_values,axis=1), linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_pca2[:,0], shap_pca2[:,1], c=np.sum(shap_values,axis=1), linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_pca2[:,0], shap_pca2[:,1], c=X[\"Age\"], linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_pca2[:,0], shap_pca2[:,1], c=X[\"Sex\"], linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_pca2 = PCA(n_components=2).fit(shap_values[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?shap_pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_pca2.components_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_embedded = TSNE(n_components=2, perplexity=50).fit_transform(shap_values[:1000,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_embedded[:,0], shap_embedded[:,1], c=np.sum(shap_values[:1000,:],axis=1), linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_embedded[:,0], shap_embedded[:,1], c=X[\"Age\"][:1000], linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_embedded[:,0], shap_embedded[:,1], c=X[\"Sex\"][:500], linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_embedded[:,0], shap_embedded[:,1], c=X[\"Systolic BP\"][:500], linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_pca2[:,0], shap_pca2[:,1], c=X[\"Systolic BP\"], linewidth=0, alpha=0.5, cmap=shap.plots.red_blue)\n",
    "cb = pl.colorbar(label=\"Model output\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1 - Simple Inconsistency Example\n",
    "\n",
    "Here we create synthetic data to make XGBoost build the Model A and Model B from Figure 1 of the Tree SHAP paper. We then compute both individualized feature importances using Tree SHAP and Saabas, and global feature importances using Tree SHAP, gain, split count, and permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import shap\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model A\n",
    "\n",
    "This is just a simple AND function with a small amount of noise to force the creation of the left child split. Feature 0 is Fever and feature 1 is Cough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "X = np.zeros((N,2))\n",
    "X[:1000,0] = 1\n",
    "X[:500,1] = 1\n",
    "X[1000:1500,1] = 1\n",
    "yA = 80 * (X[:,0] * X[:,1]) + 1e-4 * ((X[:,0] == 0) * (X[:,1] == 0)) # last term forces the creation of left split\n",
    "Xd = xgb.DMatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with single tree\n",
    "XdA = xgb.DMatrix(X, label=yA)\n",
    "modelA = xgb.train({\n",
    "    'eta': 1, 'max_depth': 3, 'base_score': 0, \"lambda\": 0\n",
    "}, XdA, 1)\n",
    "print(modelA.get_dump(with_stats=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model B\n",
    "\n",
    "This is identical to Model A, except Cough is more important because it has its own marginal effect in addition to the original AND function in Model A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yB = yA + X[:,1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with single tree\n",
    "XdB = xgb.DMatrix(X, label=yB)\n",
    "modelB = xgb.train({\n",
    "    'eta': 1, 'max_depth': 3, 'base_score': 0, \"lambda\": 0\n",
    "}, XdB, 1)\n",
    "print(modelB.get_dump(with_stats=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_valuesA = modelA.predict(Xd, pred_contribs=True)\n",
    "shap_valuesA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_valuesB = modelB.predict(Xd, pred_contribs=True)\n",
    "shap_valuesB[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saabas Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saabas_valuesA = modelA.predict(Xd, pred_contribs=True, approx_contribs=True)\n",
    "saabas_valuesA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saabas_valuesB = modelB.predict(Xd, pred_contribs=True, approx_contribs=True)\n",
    "saabas_valuesB[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean(abs(SHAP Values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(shap_valuesA).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(shap_valuesB).mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean(abs(Saabas Values))\n",
    "\n",
    "Note that the mean absolute Saabas values happen to be identical to the mean absolute SHAP values in this simple example, but in general this is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(saabas_valuesA).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(saabas_valuesB).mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = modelA.get_score(importance_type=\"weight\")\n",
    "splitsA_fever = tmp[\"f0\"]\n",
    "splitsA_cough = tmp[\"f1\"]\n",
    "splitsA_fever,splitsA_cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = modelB.get_score(importance_type=\"weight\")\n",
    "splitsB_fever = tmp[\"f0\"]\n",
    "splitsB_cough = tmp[\"f1\"]\n",
    "splitsB_fever,splitsB_cough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain\n",
    "\n",
    "For some reason XGBoost averages the gain instead of summing as is classically proposed by Brieman, Friedman and others. So we undo the average by multiplying by the split count. (The averaged version of the gain is also inconsistent, but just not with this example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = modelA.get_score(importance_type=\"gain\")\n",
    "gainA_fever = tmp[\"f0\"]*splitsA_fever\n",
    "gainA_cough = tmp[\"f1\"]*splitsA_cough \n",
    "total = gainA_fever+gainA_cough\n",
    "gainA_fever /= total / 100\n",
    "gainA_cough /= total / 100\n",
    "gainA_fever,gainA_cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"f0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = modelB.get_score(importance_type=\"gain\")\n",
    "gainB_fever = tmp[\"f0\"] * splitsB_fever\n",
    "gainB_cough = tmp[\"f1\"] * splitsB_cough \n",
    "total = gainB_fever + gainB_cough\n",
    "gainB_fever /= total / 100\n",
    "gainB_cough /= total / 100\n",
    "gainB_fever, gainB_cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"f0\"]*splitsB_fever/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"f1\"]*splitsB_cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1250000.0/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(90+10+0+0)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((90-25)**2 + (10-25)**2 + (0-25)**2 + (0-25)**2)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((90-25)**2 + (10-25)**2 + (0-25)**2 + (0-25)**2)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((90-50)**2 + (10-50)**2 + (0-0)**2 + (0-0)**2)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation\n",
    "\n",
    "XGBoost does not implement permtation importance so we compute it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_importance(model, y):\n",
    "    vals_fever = []\n",
    "    Xtmp = X.copy()\n",
    "    inds = list(range(Xtmp.shape[0]))\n",
    "    for i in range(1000):\n",
    "        np.random.shuffle(inds)\n",
    "        Xtmp[:,0] = Xtmp[inds,0]\n",
    "        err = y - model.predict(xgb.DMatrix(Xtmp))\n",
    "        vals_fever.append(np.mean(np.sqrt(err*err)))\n",
    "    \n",
    "    vals_cough = []\n",
    "    Xtmp = X.copy()\n",
    "    inds = list(range(Xtmp.shape[0]))\n",
    "    for i in range(1000):\n",
    "        np.random.shuffle(inds)\n",
    "        Xtmp[:,1] = Xtmp[inds,1]\n",
    "        err = y - model.predict(xgb.DMatrix(Xtmp))\n",
    "        vals_cough.append(np.mean(np.sqrt(err*err)))\n",
    "    return np.mean(vals_fever),np.mean(vals_cough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuteA_fever,permuteA_cough = permute_importance(modelA, yA)\n",
    "permuteA_fever,permuteA_cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuteB_fever,permuteB_cough = permute_importance(modelB, yB)\n",
    "permuteB_fever,permuteB_cough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Split Count\n",
    "\n",
    "The weighted split count is another option in XGBoost, it is not inconsistent in this example, but is for other scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA.get_score(importance_type=\"cover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.get_score(importance_type=\"cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plot\n",
    "\n",
    "Here we make the core bar plot for Figure 1 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fever\n",
    "f = pl.figure(figsize=(7,6))\n",
    "pl.subplot(1,2,1)\n",
    "d = 2\n",
    "values_A = [\n",
    "    permuteA_fever,\n",
    "    splitsA_fever,\n",
    "    gainA_fever,\n",
    "    np.abs(shap_valuesA).mean(0)[0],\n",
    "    saabas_valuesA[0,0],\n",
    "    shap_valuesA[0,0]\n",
    "]\n",
    "display_A = [str(int(round(v))) for v in values_A]\n",
    "display_A[2] = str(int(display_A[2]))+\"%\"\n",
    "positions_A = [\n",
    "    1,\n",
    "    4,\n",
    "    7,\n",
    "    10,\n",
    "    13+d,\n",
    "    16+d\n",
    "]\n",
    "values_B = [\n",
    "    permuteA_cough,\n",
    "    splitsA_cough,\n",
    "    gainA_cough,\n",
    "    np.abs(shap_valuesA).mean(0)[1],\n",
    "    saabas_valuesA[0,1],\n",
    "    shap_valuesA[0,1]\n",
    "]\n",
    "display_B = [str(int(round(v))) for v in values_B]\n",
    "display_B[2] = str(int(display_B[2]))+\"%\"\n",
    "positions_B = [\n",
    "    0,\n",
    "    3,\n",
    "    6,\n",
    "    9,\n",
    "    12+d,\n",
    "    15+d\n",
    "]\n",
    "pl.barh(positions_A, values_A, color=\"#008BE0\")\n",
    "pl.barh(positions_B, values_B, color=\"#008BE0\")\n",
    "pl.yticks([])\n",
    "pl.axis('off')\n",
    "for i, v in enumerate(values_A):\n",
    "    pl.text(v + 3, positions_A[i]-0.25, str(display_A[i]), color='#008BE0', fontweight='bold')\n",
    "for i, v in enumerate(values_B):\n",
    "    pl.text(v + 3, positions_B[i]-0.25, str(display_B[i]), color='#008BE0', fontweight='bold')\n",
    "\n",
    "# cough\n",
    "pl.subplot(1,2,2)\n",
    "d = 2\n",
    "values_A = [\n",
    "    permuteB_fever,\n",
    "    splitsB_fever,\n",
    "    gainB_fever,\n",
    "    np.abs(shap_valuesB).mean(0)[0],\n",
    "    saabas_valuesB[0,0],\n",
    "    shap_valuesB[0,0]\n",
    "]\n",
    "display_A = [str(int(round(v))) for v in values_A]\n",
    "display_A[2] = display_A[2]+\"%\"\n",
    "positions_A = [\n",
    "    1,\n",
    "    4,\n",
    "    7,\n",
    "    10,\n",
    "    13+d,\n",
    "    16+d\n",
    "]\n",
    "values_B = [\n",
    "    permuteB_cough,\n",
    "    splitsB_cough,\n",
    "    gainB_cough,\n",
    "    np.abs(shap_valuesB).mean(0)[1],\n",
    "    saabas_valuesB[0,1],\n",
    "    shap_valuesB[0,1]\n",
    "]\n",
    "display_B = [str(int(round(v))) for v in values_B]\n",
    "display_B[2] = str(int(display_B[2]))+\"%\"\n",
    "positions_B = [\n",
    "    0,\n",
    "    3,\n",
    "    6,\n",
    "    9,\n",
    "    12+d,\n",
    "    15+d\n",
    "]\n",
    "pl.barh(positions_A, values_A, color=\"#FF165A\")\n",
    "pl.barh(positions_B, values_B, color=\"#FF165A\")\n",
    "pl.yticks([])\n",
    "pl.axis('off')\n",
    "for i, v in enumerate(values_A):\n",
    "    pl.text(v + 3, positions_A[i]-0.25, str(display_A[i]), color='#FF165A', fontweight='bold')\n",
    "for i, v in enumerate(values_B):\n",
    "    pl.text(v + 3, positions_B[i]-0.25, str(display_B[i]), color='#FF165A', fontweight='bold')\n",
    "    \n",
    "pl.show()\n",
    "#pl.savefig(\"data/bar.pdf\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import shap\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iml.common import convert_to_instance, convert_to_model, match_instance_to_data, match_model_to_data, convert_to_instance_with_index\n",
    "from iml.explanations import AdditiveExplanation\n",
    "from iml.links import convert_to_link, IdentityLink\n",
    "from iml.datatypes import convert_to_data, DenseData\n",
    "import logging\n",
    "from iml.explanations import AdditiveExplanation\n",
    "\n",
    "log = logging.getLogger('shap')\n",
    "from shap import KernelExplainer\n",
    "class IMEExplainer(KernelExplainer):\n",
    "    \"\"\" This is an implementation of the IME explanation method (aka. Shapley sampling values)\n",
    "    \n",
    "    IME was proposed in \"An Efficient Explanation of Individual Classifications using Game Theory\",\n",
    "    Erik Å trumbelj, Igor Kononenko, JMLR 2010\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, data, **kwargs):\n",
    "        # silence warning about large datasets\n",
    "        level = log.level\n",
    "        log.setLevel(logging.ERROR)\n",
    "        super(IMEExplainer, self).__init__(model, data, **kwargs)\n",
    "        log.setLevel(level)\n",
    "    \n",
    "    def explain(self, incoming_instance, **kwargs):\n",
    "        # convert incoming input to a standardized iml object\n",
    "        instance = convert_to_instance(incoming_instance)\n",
    "        match_instance_to_data(instance, self.data)\n",
    "        \n",
    "        # pick a reasonable number of samples if the user didn't specify how many they wanted\n",
    "        self.nsamples = kwargs.get(\"nsamples\", 0)\n",
    "        if self.nsamples == 0:\n",
    "            self.nsamples = 1000 * self.P\n",
    "        \n",
    "        # divide up the samples among the features\n",
    "        self.nsamples_each = np.ones(self.P, dtype=np.int64) * 2 * (self.nsamples // (self.P * 2))\n",
    "        for i in range((self.nsamples % (self.P * 2)) // 2):\n",
    "            self.nsamples_each[i] += 2\n",
    "        \n",
    "        model_out = self.model.f(instance.x)\n",
    "        \n",
    "        # explain every feature\n",
    "        phi = np.zeros(self.P)\n",
    "        self.X_masked = np.zeros((self.nsamples_each.max(), X.shape[1]))\n",
    "        for i in range(self.P):\n",
    "            phi[i] = self.ime(i, self.model.f, instance.x, self.data.data, nsamples=self.nsamples_each[i])\n",
    "        phi = np.array(phi)\n",
    "        \n",
    "        return AdditiveExplanation(self.link.f(1), self.link.f(1), phi, np.zeros(len(phi)), instance, self.link,\n",
    "                                   self.model, self.data)\n",
    "        \n",
    "        \n",
    "    def ime(self, j, f, x, X, nsamples=10):\n",
    "        assert nsamples % 2 == 0, \"nsamples must be divisible by 2!\"\n",
    "        X_masked = self.X_masked[:nsamples,:]\n",
    "        inds = np.arange(X.shape[1])\n",
    "\n",
    "        for i in range(0, nsamples//2):\n",
    "            np.random.shuffle(inds)\n",
    "            pos = np.where(inds == j)[0][0]\n",
    "            rind = np.random.randint(X.shape[0])\n",
    "            X_masked[i,:] = x\n",
    "            X_masked[i,inds[pos+1:]] = X[rind,inds[pos+1:]]\n",
    "            X_masked[-(i+1),:] = x\n",
    "            X_masked[-(i+1),inds[pos:]] = X[rind,inds[pos:]]\n",
    "            \n",
    "        evals = f(X_masked)\n",
    "        \n",
    "        evals_on = evals[:nsamples//2]\n",
    "        evals_off = evals[nsamples//2:][::-1]\n",
    "        \n",
    "        return np.mean(evals[:nsamples//2] - evals[nsamples//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tree_shap_times = []\n",
    "kernel_shap_times = []\n",
    "ime_times = []\n",
    "nreps = 10\n",
    "\n",
    "N = 1000\n",
    "X_full = np.random.randn(N, 20)\n",
    "y = np.random.randn(N)\n",
    "\n",
    "for M in range(4,8):\n",
    "    ts = []\n",
    "    tree_shap_time = 0\n",
    "    kernel_shap_time = 0\n",
    "    ime_time = 0\n",
    "    for k in tqdm(range(nreps)):\n",
    "#         print()\n",
    "         #+ ((X > 0).sum(1) % 2)\n",
    "        X = X_full[:,:M]\n",
    "\n",
    "        model = xgboost.train({\"eta\": 1}, xgboost.DMatrix(X, y), 1000)\n",
    "\n",
    "        def f(x):\n",
    "            return model.predict(xgboost.DMatrix(x))\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        shap_values = shap.TreeExplainer(model).shap_values(X)\n",
    "        tree_shap_time += time.time() - start\n",
    "#         print(\"Tree SHAP:\", tree_shap_time, \"seconds\")\n",
    "\n",
    "        shap_stddev = shap_values.std(0)[:-1].mean()\n",
    "\n",
    "#         print(\"mean std dev of SHAP values over samples:\", shap_stddev)\n",
    "\n",
    "        e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "        nsamples = 200\n",
    "#         print(shap_stddev/20)\n",
    "        for j in range(2000):\n",
    "            #print(nsamples)\n",
    "            start = time.time()\n",
    "            std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "            iter_time = (time.time() - start)/50\n",
    "            #print(std_dev)\n",
    "            if std_dev < shap_stddev/20:\n",
    "#                 print(\"KernelExplainer\", nsamples)\n",
    "#                 print(\"KernelExplainer\", std_dev)\n",
    "#                 print(\"KernelExplainer\", iter_time, \"seconds\")\n",
    "                kernel_shap_time += iter_time * 1000\n",
    "                break\n",
    "            nsamples += int(nsamples * 0.5)\n",
    "\n",
    "        e = IMEExplainer(f, X.mean(0).reshape(1,M))\n",
    "        nsamples = 200\n",
    "        for j in range(2000):\n",
    "        #     print()\n",
    "        #     print(nsamples)\n",
    "            start = time.time()\n",
    "            std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "        #     print(\"time\", (time.time() - start)/50)\n",
    "        #     print(std_dev)\n",
    "            iter_time = (time.time() - start)/50\n",
    "            if std_dev < shap_stddev/20:\n",
    "#                 print(\"IMEExplainer\", nsamples)\n",
    "#                 print(\"IMEExplainer\", std_dev)\n",
    "#                 print(\"IMEExplainer\", iter_time, \"seconds\")\n",
    "                ime_time += iter_time * 1000\n",
    "                break\n",
    "            nsamples += int(nsamples * 0.5)\n",
    "\n",
    "    tree_shap_times.append(tree_shap_time / nreps)\n",
    "    kernel_shap_times.append(kernel_shap_time / nreps)\n",
    "    ime_times.append(ime_time / nreps)\n",
    "    print(\"TreeExplainer\", tree_shap_times[-1])\n",
    "    print(\"KernelExplainer\", kernel_shap_times[-1])\n",
    "    print(\"IMEExplainer\", ime_times[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(xgboost.DMatrix(X)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.TreeExplainer(model).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=100) for i in range(50)]).std(0)[:-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.KernelExplainer(f, X.mean(0).reshape(1,M))\n",
    "nsamples = 200\n",
    "print(shap_stddev/20)\n",
    "for j in range(2000):\n",
    "    print(nsamples)\n",
    "    start = time.time()\n",
    "    std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "    iter_time = time.time() - start)/50\n",
    "    print(std_dev)\n",
    "    if std_dev < shap_stddev/20:\n",
    "        print(nsamples)\n",
    "        break\n",
    "    nsamples += int(nsamples * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = IMEExplainer(f, X.mean(0).reshape(1,M))\n",
    "nsamples = 200\n",
    "print(shap_stddev/20)\n",
    "for j in range(2000):\n",
    "    print()\n",
    "    print(nsamples)\n",
    "    start = time.time()\n",
    "    std_dev = np.vstack([e.shap_values(X[:1,:], silent=True, nsamples=nsamples) for i in range(50)]).std(0)[:-1].mean()\n",
    "    print(\"time\", (time.time() - start)/50)\n",
    "    print(std_dev)\n",
    "    if std_dev < shap_stddev/20:\n",
    "        print(nsamples)\n",
    "        break\n",
    "    nsamples += int(nsamples * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.56939 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([IMEExplainer(f, X.mean(0).reshape(1,M)).shap_values(X[:1,:], silent=True, nsamples=1000)[0,0] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[shap.KernelExplainer(f, X.mean(0).reshape(1,M)).shap_values(X[:1,:], silent=True, nsamples=1000)[0,0] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return model.predict(xgboost.DMatrix(x))\n",
    "\n",
    "start = time.time()\n",
    "shap_values2 = shap.KernelExplainer(f, X.mean(0).reshape(1,M)).shap_values(X)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "IMEExplainer(f, X.mean(0).reshape(1,M)).shap_values(X)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

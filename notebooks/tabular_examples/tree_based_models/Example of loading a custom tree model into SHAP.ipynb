{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of loading a custom tree model into SHAP\n",
    "\n",
    "This notebook shows how to pass a custom tree ensemble model into SHAP for explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import shap\n",
    "import sklearn\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple regression tree model\n",
    "\n",
    "Here we define a simple regression tree and then load it into SHAP as a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.boston()\n",
    "\n",
    "orig_model = sklearn.tree.DecisionTreeRegressor(max_depth=2)\n",
    "orig_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = sklearn.tree.export_graphviz(orig_model, out_file=None, filled=True, rounded=True, special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the arrays that define the tree\n",
    "children_left = orig_model.tree_.children_left\n",
    "children_right = orig_model.tree_.children_right\n",
    "children_default = children_right.copy() # because sklearn does not use missing values\n",
    "features = orig_model.tree_.feature\n",
    "thresholds = orig_model.tree_.threshold\n",
    "values = orig_model.tree_.value.reshape(orig_model.tree_.value.shape[0], 1)\n",
    "node_sample_weight = orig_model.tree_.weighted_n_node_samples\n",
    "\n",
    "print(\"     children_left\", children_left) # note that negative children values mean this is a leaf node\n",
    "print(\"    children_right\", children_right)\n",
    "print(\"  children_default\", children_default)\n",
    "print(\"          features\", features)\n",
    "print(\"        thresholds\", thresholds.round(3))\n",
    "print(\"            values\", values.round(3))\n",
    "print(\"node_sample_weight\", node_sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom tree model\n",
    "tree_dict = {\n",
    "    \"children_left\": children_left,\n",
    "    \"children_right\": children_right,\n",
    "    \"children_default\": children_default,\n",
    "    \"features\": features,\n",
    "    \"thresholds\": thresholds,\n",
    "    \"values\": values,\n",
    "    \"node_sample_weight\": node_sample_weight\n",
    "}\n",
    "model = {\n",
    "    \"trees\": [tree_dict]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the ingested SHAP model (a TreeEnsemble object) makes the\n",
    "# same predictions as the original model\n",
    "assert np.abs(explainer.model.predict(X) - orig_model.predict(X)).max() < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the SHAP values sum up to the model output (this is the local accuracy property)\n",
    "assert np.abs(explainer.expected_value + explainer.shap_values(X).sum(1) - orig_model.predict(X)).max() < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GBM classification model (with 2 trees)\n",
    "\n",
    "Here we define a simple gradient-boosting classifier and then load it into SHAP as a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,y2 = shap.datasets.adult()\n",
    "orig_model2 = sklearn.ensemble.GradientBoostingClassifier(n_estimators=2)\n",
    "orig_model2.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the info of the first tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tmp = orig_model2.estimators_[0][0].tree_\n",
    "\n",
    "# extract the arrays that define the tree\n",
    "children_left1 = tree_tmp.children_left\n",
    "children_right1 = tree_tmp.children_right\n",
    "children_default1 = children_right1.copy() # because sklearn does not use missing values\n",
    "features1 = tree_tmp.feature\n",
    "thresholds1 = tree_tmp.threshold\n",
    "values1 = tree_tmp.value.reshape(tree_tmp.value.shape[0], 1)\n",
    "node_sample_weight1 = tree_tmp.weighted_n_node_samples\n",
    "\n",
    "print(\"     children_left1\", children_left1) # note that negative children values mean this is a leaf node\n",
    "print(\"    children_right1\", children_right1)\n",
    "print(\"  children_default1\", children_default1)\n",
    "print(\"          features1\", features1)\n",
    "print(\"        thresholds1\", thresholds1.round(3))\n",
    "print(\"            values1\", values1.round(3))\n",
    "print(\"node_sample_weight1\", node_sample_weight1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the info of the second tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tmp = orig_model2.estimators_[1][0].tree_\n",
    "\n",
    "# extract the arrays that define the tree\n",
    "children_left2 = tree_tmp.children_left\n",
    "children_right2 = tree_tmp.children_right\n",
    "children_default2 = children_right2.copy() # because sklearn does not use missing values\n",
    "features2 = tree_tmp.feature\n",
    "thresholds2 = tree_tmp.threshold\n",
    "values2 = tree_tmp.value.reshape(tree_tmp.value.shape[0], 1)\n",
    "node_sample_weight2 = tree_tmp.weighted_n_node_samples\n",
    "\n",
    "print(\"     children_left2\", children_left2) # note that negative children values mean this is a leaf node\n",
    "print(\"    children_right2\", children_right2)\n",
    "print(\"  children_default2\", children_default2)\n",
    "print(\"          features2\", features2)\n",
    "print(\"        thresholds2\", thresholds2.round(3))\n",
    "print(\"            values2\", values2.round(3))\n",
    "print(\"node_sample_weight2\", node_sample_weight2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of SHAP Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom tree model\n",
    "tree_dicts = [\n",
    "    {\n",
    "        \"children_left\": children_left1,\n",
    "        \"children_right\": children_right1,\n",
    "        \"children_default\": children_default1,\n",
    "        \"features\": features1,\n",
    "        \"thresholds\": thresholds1,\n",
    "        \"values\": values1 * orig_model2.learning_rate,\n",
    "        \"node_sample_weight\": node_sample_weight1\n",
    "    },\n",
    "    {\n",
    "        \"children_left\": children_left2,\n",
    "        \"children_right\": children_right2,\n",
    "        \"children_default\": children_default2,\n",
    "        \"features\": features2,\n",
    "        \"thresholds\": thresholds2,\n",
    "        \"values\": values2 * orig_model2.learning_rate,\n",
    "        \"node_sample_weight\": node_sample_weight2\n",
    "    },\n",
    "]\n",
    "model2 = {\n",
    "    \"trees\": tree_dicts,\n",
    "    \"base_offset\": scipy.special.logit(orig_model2.init_.class_prior_[1]),\n",
    "    \"tree_output\": \"log_odds\",\n",
    "    \"objective\": \"binary_crossentropy\",\n",
    "    \"input_dtype\": np.float32, # this is what type the model uses the input feature data\n",
    "    \"internal_dtype\": np.float64 # this is what type the model uses for values and thresholds\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a background dataset for us to use based on people near a 0.95 cutoff\n",
    "vs = np.abs(orig_model2.predict_proba(X2)[:,1] - 0.95)\n",
    "inds = np.argsort(vs)\n",
    "inds = inds[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an explainer that explains the probability output of the model\n",
    "explainer2 = shap.TreeExplainer(model2, X2.iloc[inds,:], feature_dependence=\"independent\", model_output=\"probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the ingested SHAP model (a TreeEnsemble object) makes the\n",
    "# same predictions as the original model\n",
    "assert np.abs(explainer2.model.predict(X2, output=\"probability\") - orig_model2.predict_proba(X2)[:,1]).max() < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the sum of the SHAP values equals the model output\n",
    "shap_sum = explainer2.expected_value + explainer2.shap_values(X2.iloc[:,:]).sum(1)\n",
    "assert np.abs(shap_sum - orig_model2.predict_proba(X2)[:,1]).max() < 1e-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

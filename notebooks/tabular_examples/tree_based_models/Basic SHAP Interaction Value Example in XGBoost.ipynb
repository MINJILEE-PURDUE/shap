{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic SHAP Interaction Value Example in XGBoost\n",
    "\n",
    "This notebook shows how the SHAP interaction values for a very simple function are computed. We start with a simple linear function, and then add an interaction term to see how it changes the SHAP values and the SHAP interaction values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a linear function with no interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some binary data and a linear outcome with an interaction term\n",
    "# note we make the features in X perfectly independent of each other to make\n",
    "# it easy to solve for the exact SHAP values\n",
    "N = 2000\n",
    "X = np.zeros((N,5))\n",
    "X[:1000,0] = 1\n",
    "X[:500,1] = 1\n",
    "X[1000:1500,1] = 1\n",
    "X[:250,2] = 1\n",
    "X[500:750,2] = 1\n",
    "X[1000:1250,2] = 1\n",
    "X[1500:1750,2] = 1\n",
    "X[:,0:3] -= 0.5\n",
    "y = 2*X[:,0] - 3*X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the variables are independent\n",
    "np.cov(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and mean centered\n",
    "X.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with single tree\n",
    "Xd = xgboost.DMatrix(X, label=y)\n",
    "model = xgboost.train({\n",
    "    'eta':1, 'max_depth':3, 'base_score': 0, \"lambda\": 0\n",
    "}, Xd, 1)\n",
    "print(\"Model error =\", np.linalg.norm(y-model.predict(Xd)))\n",
    "print(model.get_dump(with_stats=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the SHAP values add up to marginal predictions\n",
    "pred = model.predict(Xd, output_margin=True)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(Xd)\n",
    "np.abs(shap_values.sum(1) + explainer.expected_value - pred).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we build a summary plot we see that only features 1 and 2 have any effect, and that their effects only have two possible magnitudes (one for -0.5 and for 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear model\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n",
    "lr_pred = lr.predict(X)\n",
    "lr.coef_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the computed SHAP values match the true SHAP values\n",
    "# (we can compute the true SHAP values directly for this simple case)\n",
    "main_effect_shap_values = lr.coef_ * (X - X.mean(0))\n",
    "np.linalg.norm(shap_values - main_effect_shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Interaction Values\n",
    "\n",
    "Note that when there are no interactions present the SHAP interaction values are just a diagonal matrix with the SHAP values on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(Xd)\n",
    "shap_interaction_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the SHAP interaction values sum to the marginal predictions\n",
    "np.abs(shap_interaction_values.sum((1,2)) + explainer.expected_value - pred).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the main effects from the SHAP interaction values match those from a linear model\n",
    "dinds = np.diag_indices(shap_interaction_values.shape[1])\n",
    "total = 0\n",
    "for i in range(N):\n",
    "    for j in range(5):\n",
    "        total += np.abs(shap_interaction_values[i,j,j] - main_effect_shap_values[i,j])\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a linear model with one interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some binary data and a linear outcome with an interaction term\n",
    "# note we make the features in X perfectly independent of each other to make\n",
    "# it easy to solve for the exact SHAP values\n",
    "N = 2000\n",
    "X = np.zeros((N,5))\n",
    "X[:1000,0] = 1\n",
    "\n",
    "X[:500,1] = 1\n",
    "X[1000:1500,1] = 1\n",
    "\n",
    "X[:250,2] = 1\n",
    "X[500:750,2] = 1\n",
    "X[1000:1250,2] = 1\n",
    "X[1500:1750,2] = 1\n",
    "\n",
    "X[:125,3] = 1\n",
    "X[250:375,3] = 1\n",
    "X[500:625,3] = 1\n",
    "X[750:875,3] = 1\n",
    "X[1000:1125,3] = 1\n",
    "X[1250:1375,3] = 1\n",
    "X[1500:1625,3] = 1\n",
    "X[1750:1875,3] = 1\n",
    "X[:,:4] -= 0.4999 # we can't exactly mean center the data or XGBoost has trouble finding the splits\n",
    "y = 2* X[:,0] - 3 * X[:,1] + 2 * X[:,1] * X[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with single tree\n",
    "Xd = xgboost.DMatrix(X, label=y)\n",
    "model = xgboost.train({\n",
    "    'eta':1, 'max_depth':4, 'base_score': 0, \"lambda\": 0\n",
    "}, Xd, 1)\n",
    "print(\"Model error =\", np.linalg.norm(y-model.predict(Xd)))\n",
    "print(model.get_dump(with_stats=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the SHAP values add up to marginal predictions\n",
    "pred = model.predict(Xd, output_margin=True)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(Xd)\n",
    "np.abs(shap_values.sum(1) + explainer.expected_value - pred).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we build a summary plot we see that now only features 3 and 4 don't matter, and that feature 1 can have four possible effect sizes due to interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n",
    "lr_pred = lr.predict(X)\n",
    "lr.coef_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the SHAP values no longer match the main effects because they now include interaction effects\n",
    "main_effect_shap_values = lr.coef_ * (X - X.mean(0))\n",
    "np.linalg.norm(shap_values - main_effect_shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP interaction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP interaction contributions:\n",
    "shap_interaction_values = explainer.shap_interaction_values(Xd)\n",
    "shap_interaction_values[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the SHAP interaction values sum to the marginal predictions\n",
    "np.abs(shap_interaction_values.sum((1,2)) + explainer.expected_value - pred).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the main effects from the SHAP interaction values match those from a linear model.\n",
    "# while the main effects no longer match the SHAP values when interactions are present, they do match\n",
    "# the main effects on the diagonal of the SHAP interaction value matrix\n",
    "dinds = np.diag_indices(shap_interaction_values.shape[1])\n",
    "total = 0\n",
    "for i in range(N):\n",
    "    for j in range(5):\n",
    "        total += np.abs(shap_interaction_values[i,j,j] - main_effect_shap_values[i,j])\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we build a dependence plot for feature 0 we that it only takes two values and that these values are entirely dependent on the value of the feature (the value of feature 0 entirely determines it's effect because it has no interactions with other features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(0, shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast if we build a dependence plot for feature 2 we see that it takes 4 possible values and they are not entirely determined by the value of feature 2, instead they also depend on the value of feature 3. This vertical spread in a dependence plot represents the effects of non-linear interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(2, shap_values, X)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

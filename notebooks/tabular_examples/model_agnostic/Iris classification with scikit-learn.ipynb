{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris classification with scikit-learn\n",
    "\n",
    "Here we use the well-known Iris species dataset to illustrate how SHAP can explain the output of many different model types, from k-nearest neighbors, to neural networks. This dataset is very small, with only a 150 samples. We use a random set of 130 for training and 20 for testing the models. Because this is a small dataset with only a few features we use the entire training dataset for the background. In problems with more features we would want to pass only the median of the training dataset, or weighted k-medians. While we only have a few samples, the prediction problem is fairly easy and all methods acheive perfect accuracy. What's interesting is how different methods sometimes rely on different sets of features for their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "import time\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)\n",
    "\n",
    "# rather than use the whole training set to estimate expected values, we could summarize with\n",
    "# a set of weighted kmeans, each weighted by the number of points they represent. But this dataset\n",
    "# is so small we don't worry about it\n",
    "#X_train_summary = shap.kmeans(X_train, 50)\n",
    "\n",
    "def print_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "print_accuracy(knn.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain a single prediction from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(knn.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test.iloc[0,:])\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain all the predictions in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine with a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = sklearn.svm.SVC(kernel='linear', probability=True)\n",
    "svc_linear.fit(X_train, Y_train)\n",
    "print_accuracy(svc_linear.predict)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(svc_linear.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine with a radial basis function kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = sklearn.svm.SVC(kernel='rbf', probability=True)\n",
    "svc_linear.fit(X_train, Y_train)\n",
    "print_accuracy(svc_linear.predict)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(svc_linear.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_lr = sklearn.linear_model.LogisticRegression()\n",
    "linear_lr.fit(X_train, Y_train)\n",
    "print_accuracy(linear_lr.predict)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(linear_lr.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree \n",
    "dtree = sklearn.tree.DecisionTreeClassifier(min_samples_split=2)\n",
    "dtree.fit(X_train, Y_train)\n",
    "print_accuracy(dtree.predict)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(dtree.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rforest = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)\n",
    "rforest.fit(X_train, Y_train)\n",
    "print_accuracy(rforest.predict)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(rforest.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=0)\n",
    "nn.fit(X_train, Y_train)\n",
    "print_accuracy(nn.predict)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(nn.predict_proba, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

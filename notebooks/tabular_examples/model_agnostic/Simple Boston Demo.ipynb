{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Boston Demo\n",
    "\n",
    "The ability to use hierarchical feature clusterings to control  PartitionExplainer is still in an Alpha state, but this notebook demonstrates how to use it right now. Note that I am releasing this to get feedback and show how I am working to address concerns about the speed of our model agnostic approaches and the impact of feature correlations. This is all as-yet unpublished work, so treat it accordingly.\n",
    "\n",
    "When given a balanced partition tree PartitionExplainer has $O(M^2)$ runtime, where $M$ is the number of input features. This is much better than the $O(2^M)$ runtime of KernelExplainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.cluster\n",
    "import matplotlib.pyplot as pl\n",
    "import xgboost\n",
    "import shap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.boston()\n",
    "#X = X.iloc[:,:4]\n",
    "model = xgboost.XGBRegressor(n_estimators=100, subsample=0.3)\n",
    "model.fit(X, y)\n",
    "\n",
    "x = X.values[0:1,:]\n",
    "refs = X.values[1:100] # use 100 samples for our background references (using the whole dataset would be slower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a hierarchal clustering of the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = sp.spatial.distance.pdist(X.fillna(X.mean()).T, metric=\"correlation\")\n",
    "cluster_matrix = sp.cluster.hierarchy.complete(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_matrix = shap.partition_tree(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the clustering\n",
    "pl.figure(figsize=(15, 6))\n",
    "pl.title('Hierarchical Clustering Dendrogram')\n",
    "pl.xlabel('sample index')\n",
    "pl.ylabel('distance')\n",
    "sp.cluster.hierarchy.dendrogram(\n",
    "    cluster_matrix,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=10.,  # font size for the x axis labels\n",
    "    labels=X.columns\n",
    ")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.common.shapley_coefficients(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the first sample with Partition Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model as a python function \n",
    "f = lambda x: model.predict(x, output_margin=True, validate_features=False)\n",
    "\n",
    "# explain the model\n",
    "# pexplainer = shap.PartitionExplainer(f, refs, cluster_matrix)\n",
    "# shap_values = pexplainer(x, npartitions=500)\n",
    "\n",
    "m = shap.maskers.Tabular(refs, hclustering=\"correlation\")\n",
    "pexplainer = shap.explainers.BruteForce(f, refs)\n",
    "p2explainer = shap.explainers.Partition(f, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = pexplainer(x, max_evals=5000)\n",
    "shap_values2 = p2explainer(x, max_evals=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with TreeExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texplainer = shap.TreeExplainer(model, refs)\n",
    "tshap_values = texplainer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(shap_values.values[0])\n",
    "pl.plot(shap_values2.values[0])\n",
    "#pl.plot(tshap_values.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexplainer = shap.PermutationExplainer(f, refs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values3 = nexplainer(x, npermutations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data = X\n",
    "batch = np.zeros((batch_size,) + data.shape[1:])\n",
    "batch_index = 0\n",
    "for i in range(npermutations):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sizes = 4\n",
    "svals = np.zeros((n_sizes, X.shape[1]))\n",
    "pvals = np.zeros((n_sizes, X.shape[1]))\n",
    "nvals = np.zeros((n_sizes, X.shape[1]))\n",
    "sizes = np.linspace(100, 500000, n_sizes)\n",
    "for i,s in enumerate(sizes):\n",
    "    s = int(s)\n",
    "    s -= s % 2\n",
    "    pvals[i] = pexplainer(x, nsamples=s).values[0]\n",
    "    svals[i] = sexplainer(x, nsamples=s).values[0]\n",
    "    nvals[i] = nexplainer(x, npermutations=s).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(svals.shape[1]):\n",
    "    pl.plot(sizes, svals[:,i].T)\n",
    "    pl.plot(sizes, pvals[:,i].T)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(sizes, svals[:,0].T)\n",
    "pl.plot(sizes, pvals[:,0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(shap_values2.values[0], label=\"TreeExplainer\")\n",
    "pl.plot(shap_values.values[0], label=\"PartitionExplainer\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bit70c3c8a7f18d4fbeb36d0e3002bf56c5",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Text Data Explanation Benchmarking: Multi-class Emotion Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This notebook demonstrates how to use the benchmark utility to benchmark the performance of partition explainer on text data. In this demo, we showcase partition explainer performance on text prediction model on emotion dataset provided by hugging face and the Emo-MobileBERT (https://huggingface.co/lordtt13/emo-mobilebert). There are a total of four emotions that the model can predict: happy, sad, angry and others. The metrics used to evaluate are \"keep positive\" and \"keep negative\". The masker used is Text Masker. The performance on each output emotion s well as the mean output are shown. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import shap\n",
    "import scipy as sp\n",
    "import nlp\n",
    "import torch\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "source": [
    "### Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = nlp.load_dataset(\"emo\", split = [\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'others', 1: 'happy', 2: 'sad', 3: 'angry'}\n",
    "labels=list(id2label.values())\n",
    "label2id = {}\n",
    "for i,label in enumerate(labels):\n",
    "    label2id[label]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'text':[],\n",
    "     'emotion':[]}\n",
    "for val in train:\n",
    "    if id2label[val['label']]!='others':\n",
    "        data['text'].append(val['text'])\n",
    "        data['emotion'].append(id2label[val['label']])\n",
    "        \n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "source": [
    "### Load Model and Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"lordtt13/emo-mobilebert\",use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"lordtt13/emo-mobilebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}